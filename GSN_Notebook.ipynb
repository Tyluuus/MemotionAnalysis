{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GSN_Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tyluuus/MemotionAnalysis/blob/udpates/GSN_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GSN21Z Projekt "
      ],
      "metadata": {
        "id": "1rBvyUIKhIm3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Celem projektu będzie realizacja tasku B znajdującego się pod challengem Memotion na platformie Kaggle: https://www.kaggle.com/williamscott701/memotion-dataset-7k\n",
        "\n",
        "\n",
        "Treść zadania: *Task B- Humor Classification: Given an Internet meme, the system has to identify the type of humor expressed. The categories are sarcastic, humorous, and offensive meme. If a meme does not fall under any of these categories, then it is marked as another meme. A meme can have more than one category.*\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HzZuFchUhK59"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset: W datasecie znajduje się 6992 memów pobranych z platformy reddit oraz oznaczonych z wykorzystaniem usługi Amazon Mechanical Turk. Oznaczenia znajdują się w pliku csv, który zawiera: \n",
        "1.   Nazwę pliku z memem\n",
        "2.   Tekst uzyskany z wykorzystaniem OCR\n",
        "3.   Tekst poprawiony\n",
        "4.   Klasa humorystyczna\n",
        "5.   Klasa sarkastyczna\n",
        "6.   Klasa ofensywna\n",
        "7.   Klasa motywacyjna\n"
      ],
      "metadata": {
        "id": "E0WtWWldhMuM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "mXDbxxTh3ydL",
        "outputId": "32614539-e92b-4f43-f340-4b2f5c2f5375",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sklonowanie repozytorium z githuba - pobranie plików składających się na dataset - zdjęć oraz pliku csv\n",
        "#pobierane są również pliki niezbędne do wczytania modelu sieci\n",
        "!git clone https://github.com/Tyluuus/MemotionAnalysis.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qo0BnasUhoIN",
        "outputId": "cb8a345a-9152-4a25-8234-4f22ce1aa410"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MemotionAnalysis'...\n",
            "remote: Enumerating objects: 7097, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 7097 (delta 19), reused 3 (delta 1), pack-reused 7063\u001b[K\n",
            "Receiving objects: 100% (7097/7097), 862.50 MiB | 25.89 MiB/s, done.\n",
            "Resolving deltas: 100% (58/58), done.\n",
            "Checking out files: 100% (13992/13992), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDlvwtuTQCHi",
        "outputId": "c1cc02d0-bdab-4f6f-9027-47a6dfa65de7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 7.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 29.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 57.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 74.1 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 7.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.10.3 transformers-4.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Imports\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import cv2\n",
        "import time\n",
        "import copy\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets, models\n",
        "from PIL import Image\n",
        "from google.colab.patches import cv2_imshow\n",
        "from torchtext.legacy.data import Dataset, Example, Field\n",
        "from torchtext.legacy.data import BucketIterator\n",
        "from transformers import BertModel\n",
        "from transformers import BertTokenizer\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "4aknJXfFqGaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Switch to using GPU\n",
        "\n",
        "use_gpu = torch.cuda.is_available()\n",
        "if use_gpu:\n",
        "    print(\"Using CUDA\")"
      ],
      "metadata": {
        "id": "hEbiFkj3tuUC",
        "outputId": "eb404a5e-9051-4e55-b82a-810932f6eb66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using CUDA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use trained model variable\n",
        "use_trained_model = False\n",
        "save_model = True\n",
        "image_model_continue_training = False\n",
        "image_save_model_path = './drive/MyDrive/GSN_dataset/memotion_images_model_30_epoch.pt'\n",
        "text_save_model_path = './drive/MyDrive/GSN_dataset/memotion_text_model_bert_10_epochs.pt'\n",
        "image_load_model_path = './MemotionAnalysis/memotion_images_model_1_epoch.pt'\n",
        "text_load_model_path = './MemotionAnalysis/memotion_text_model_1_epoch.pt'\n",
        "image_checkpoint_path = './drive/MyDrive/GSN_dataset/checkpoint.pt'\n",
        "text_checkpoint_path = './drive/MyDrive/GSN_dataset/memotion_text_model_bert_10_epochs_checkpoint.pt'"
      ],
      "metadata": {
        "id": "B6v2cyDH1dKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_epochs = 200 # 250\n",
        "image_epochs = 25 # 20\n",
        "text_batch_size = 2\n",
        "image_batch_size = 16\n",
        "\n",
        "same_batch_size = 32"
      ],
      "metadata": {
        "id": "XYO4NllQebSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download text model for 300 epochs\n",
        "!gdown --id 1-9UMs4-3DO0acalwBUMf7rKHXBg1qV8n"
      ],
      "metadata": {
        "id": "6-kPaMfNz6Q0",
        "outputId": "1b6bbd78-c2d8-4577-ae8d-87534c117963",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-9UMs4-3DO0acalwBUMf7rKHXBg1qV8n\n",
            "To: /content/memotion_text_model_300_epoch.pt\n",
            "\r  0% 0.00/5.49M [00:00<?, ?B/s]\r100% 5.49M/5.49M [00:00<00:00, 48.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utworzenie zbioru danych na podstawie danych z Kaggle"
      ],
      "metadata": {
        "id": "6953TJgPGwop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading custom dataset into PyTorch class\n",
        "class MyCustomDataset(Dataset):\n",
        "    def __init__(self, csv_path, low_data_mode=False, debug=False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          csv_path (string): path to csv file  \n",
        "          debug (boolean): debug mode toogle\n",
        "        \"\"\"\n",
        "        # If system is in debug mode\n",
        "        self.debug = debug\n",
        "\n",
        "\n",
        "        # Read the csv_file\n",
        "        if low_data_mode==True:\n",
        "          self.data_info = pd.read_csv(csv_path, header = 6952)\n",
        "        else:\n",
        "          self.data_info = pd.read_csv(csv_path, header = 3)\n",
        "\n",
        "        # Column containing image names\n",
        "        self.image_arr = np.asarray(self.data_info.iloc[:, 1])\n",
        "\n",
        "        # Columns containing emotions classification\n",
        "        self.humour_arr = np.asarray(self.data_info.iloc[:, 4])\n",
        "        self.sarcasm_arr = np.asarray(self.data_info.iloc[:, 5])\n",
        "        self.offensive_arr = np.asarray(self.data_info.iloc[:, 6])\n",
        "        self.motivational_arr = np.asarray(self.data_info.iloc[:, 7])\n",
        "        \n",
        "\n",
        "\n",
        "        # Transforms performed on loaded image\n",
        "        self.data_transforms = transforms.Compose([\n",
        "                                      transforms.Resize((224, 224)),\n",
        "                                      transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "        \n",
        "        # Array with class vectors for each image\n",
        "        self.labels = []\n",
        "\n",
        "        # Mapping word classification to 4 numeric classes\n",
        "        for index in range(len(self.humour_arr)):\n",
        "          humour_value = class_humour_weights[self.humour_arr[index]]\n",
        "          sarcasm_value = class_sarcasm_weights[self.sarcasm_arr[index]]\n",
        "          offensive_value = class_offensive_weights[self.offensive_arr[index]]\n",
        "          motivational_value = class_motivational_weights[self.motivational_arr[index]]\n",
        "\n",
        "          if humour_value > sarcasm_value:\n",
        "            if humour_value > offensive_value:\n",
        "              if humour_value > motivational_value:\n",
        "                var = 0\n",
        "              else:\n",
        "                var = 3 \n",
        "            else:\n",
        "              if offensive_value > motivational_value:\n",
        "                var = 2\n",
        "              else: \n",
        "                var = 3\n",
        "          else:\n",
        "            if sarcasm_value > offensive_value:\n",
        "              if sarcasm_value > motivational_value:\n",
        "                var = 1\n",
        "              else:\n",
        "                var = 3\n",
        "            else: \n",
        "              if offensive_value > motivational_value: \n",
        "                var = 2\n",
        "              else:\n",
        "                var = 3\n",
        "\n",
        "          # Creating class vector\n",
        "          lab = [0.0, 0.0, 0.0, 0.0]\n",
        "          lab[var] = 1.0\n",
        "          \n",
        "          # Adding new image class vector to labels array\n",
        "          self.labels.append(lab) \n",
        "\n",
        "        # Calculate of dataset\n",
        "        self.data_len = len(self.data_info.index)\n",
        "        \n",
        "        # Set correct path to images\n",
        "        self.image_arr = images_dir + self.image_arr\n",
        "\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          index (int): index of item to get  \n",
        "\n",
        "        Returns:\n",
        "          Tuple of image and class vector as tensors\n",
        "        \"\"\"\n",
        "        img_as_img = None\n",
        "        single_image_name = None\n",
        "\n",
        "\n",
        "        try:\n",
        "          # Get image name from pandas df\n",
        "          single_image_name = self.image_arr[index]\n",
        "\n",
        "          # # Open image with PIL and convert to RGB image\n",
        "          img = Image.open(single_image_name).convert('RGB')\n",
        "          if self.debug==True:\n",
        "            print('1:', img)\n",
        "\n",
        "          # Transform image and convert to tensor\n",
        "          img_as_tensor = self.data_transforms(img)\n",
        "\n",
        "          if self.debug==True:\n",
        "            print('2:', img_as_tensor)\n",
        "\n",
        "          # Get class vector of the image from labels array\n",
        "          img_label = self.labels[index]\n",
        "\n",
        "          if self.debug==True:\n",
        "            print('3:',img_label)\n",
        "\n",
        "          # Convert class vector to tensor\n",
        "          img_label = torch.as_tensor(img_label)\n",
        "          \n",
        "          if self.debug==True:\n",
        "            print('4:',img_label)\n",
        "\n",
        "          return (img_as_tensor, img_label)\n",
        "\n",
        "        except:\n",
        "          print(\"Image loading error for:\",single_image_name)\n",
        "          return ('ERROR', torch.tensor([-1]))\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data_len"
      ],
      "metadata": {
        "id": "qAerCA5Gqd_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionaries for mapping word classification\n",
        "class_humour_weights = {\"hilarious\": 3, \"not_funny\": 0, \"very_funny\": 2, \"funny\": 1}\n",
        "class_sarcasm_weights = {\"general\": 1, \"not_sarcastic\": 0, \"twisted_meaning\": 2, \"very_twisted\": 3}\n",
        "class_offensive_weights = {\"not_offensive\": 0, \"slight\": 1, \"very_offensive\": 2, \"hateful_offensive\": 3}\n",
        "class_motivational_weights = {\"not_motivational\": 0, \"motivational\": 1}\n",
        "\n",
        "# Directory containing images\n",
        "images_dir = \"./MemotionAnalysis/images/\""
      ],
      "metadata": {
        "id": "v6vAEOVpsjht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading images into custom dataset\n",
        "dataset = MyCustomDataset('MemotionAnalysis/labels.csv', low_data_mode=False)\n",
        "\n",
        "# Loading dataset into DataLoader and setting batch_size\n",
        "b_size = same_batch_size if use_trained_model else image_batch_size\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=b_size, shuffle=False, num_workers=1)\n",
        "dataset_size = len(dataloader)"
      ],
      "metadata": {
        "id": "QyONsUPTtxnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check loaded data\n",
        "\n",
        "def imshow(inp, title=None):\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    # plt.figure(figsize=(10, 10))\n",
        "    plt.axis('off')\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)\n",
        "\n",
        "def show_databatch(inputs, classes):\n",
        "    out = torchvision.utils.make_grid(inputs)\n",
        "    imshow(out, title=[classes])\n",
        "\n",
        "# Get a batch of training data\n",
        "inputs, classes = next(iter(dataloader))\n",
        "show_databatch(inputs, classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "XQ6mkihFuZ0B",
        "outputId": "7f204f25-784a-495c-aff5-9a2975f6ee83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gałąź przetwarzania obrazów"
      ],
      "metadata": {
        "id": "NtI-EnR9hPkt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# avaliable models: vgg_16, vgg_19\n",
        "image_model_type = 'vgg_16' # 'vgg_19'"
      ],
      "metadata": {
        "id": "Orvtw4N67SIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text preprocessing\n",
        "\n",
        "meme_text = dataset.data_info.iloc[:, 3]\n",
        "\n",
        "raw_df = []\n",
        "\n",
        "for i in range(len(meme_text)):\n",
        "    raw_df.append([str(meme_text[i]), dataset.labels[i]])\n",
        "\n",
        "df = pd.DataFrame(raw_df[:-3], columns=['text', 'label'])\n",
        "\n",
        "text_field = Field(\n",
        "    sequential=True,\n",
        "    tokenize='basic_english', \n",
        "    fix_length=64,\n",
        "    lower=True\n",
        ")\n",
        "label_field = Field(sequential=False, use_vocab=False)\n",
        "# prepocess\n",
        "preprocessed_text = df['text'].apply(\n",
        "    lambda x: text_field.preprocess(x)\n",
        ")\n",
        "# load fastext simple embedding with 100d\n",
        "text_field.build_vocab(\n",
        "    preprocessed_text, \n",
        "    vectors='glove.6B.100d'\n",
        ")"
      ],
      "metadata": {
        "id": "Rptz647rV-0L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b86cceb7-f9d7-48d2-c361-71f467ba6c41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:39, 5.41MB/s]                           \n",
            "100%|█████████▉| 399999/400000 [00:14<00:00, 27557.14it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DataFrameDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame, fields: list):\n",
        "        super(DataFrameDataset, self).__init__(\n",
        "            [\n",
        "                Example.fromlist(list(r), fields) for i, r in df.iterrows()\n",
        "            ], \n",
        "            fields\n",
        "        )\n",
        "\n",
        "train_dataset, test_dataset = DataFrameDataset(\n",
        "    df=df, \n",
        "    fields=(\n",
        "        ('text', text_field),\n",
        "        ('label', label_field)\n",
        "    )\n",
        ").split(split_ratio=0.85)\n",
        "\n",
        "b_size = same_batch_size if use_trained_model else text_batch_size\n",
        "\n",
        "train_iter, test_iter = BucketIterator.splits(\n",
        "    datasets=(train_dataset, test_dataset), \n",
        "    batch_sizes=(b_size, b_size),\n",
        "    sort=False\n",
        ")"
      ],
      "metadata": {
        "id": "P6qhrLcvWeyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading pretrained vgg16\n",
        "\n",
        "!gdown --id 1f3iqJY2NDTsJP2_BFmtk5WtcfAW9nwdl"
      ],
      "metadata": {
        "id": "9lJ81u6u4Em2",
        "outputId": "f3e28655-27e5-4f68-bc9b-aebff3b70a9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1f3iqJY2NDTsJP2_BFmtk5WtcfAW9nwdl\n",
            "To: /content/vgg16_bn.pth\n",
            "100% 554M/554M [00:04<00:00, 126MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pretrained model from PyTorch\n",
        "\n",
        "vgg = None\n",
        "\n",
        "if image_model_type == 'vgg_16':\n",
        "  vgg = models.vgg16_bn()\n",
        "  vgg.load_state_dict(torch.load(\"/content/vgg16_bn.pth\")) \n",
        "  print(\"Used model: VGG16\")\n",
        "elif image_model_type == 'vgg_19':\n",
        "  vgg = models.vgg19_bn()\n",
        "  print(\"Used model: VGG19\")\n",
        "\n",
        "# Print to see network architecture\n",
        "# print(vgg16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiM8HLi7umZR",
        "outputId": "acbfa1c4-d9a7-40f1-9fef-e339b723a9ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Used model: VGG16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if use_trained_model==False:\n",
        "\n",
        "  # Class with own modification of VGG16 architecture - classifier was changed - \n",
        "  # after getting features from image there is pooling layer, next results are flattened and feed to fully connected layer with output number = 4\n",
        "  # at the end sigmoid function is used\n",
        "\n",
        "class custom_vgg(nn.Module):\n",
        "    def __init__(self, model):\n",
        "        super(custom_vgg, self).__init__()\n",
        "\n",
        "        self.features = list(model.features)\n",
        "        self.features = nn.Sequential(*self.features)\n",
        "        self.pooling = model.avgpool\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc = nn.Linear(in_features=25088, out_features=4, bias=True)\n",
        "        self.sigm = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.features(x)\n",
        "        out = self.pooling(out)\n",
        "        out = self.flatten(out)\n",
        "        out = self.fc(out)\n",
        "        out = self.sigm(out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "7-AWBscoun7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading custiom VGG16 from loaded, pretrained VGG16 model\n",
        "vgg = custom_vgg(vgg)\n",
        "\n",
        "# if use_trained_model==True:\n",
        "#   vgg16.load_state_dict(torch.load('/content/drive/MyDrive/GSN_dataset/memotion_images_model.pt'))"
      ],
      "metadata": {
        "id": "RcNr3Wd6uph2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set VGG to run on GPU\n",
        "if use_gpu:\n",
        "    vgg.cuda()\n",
        "    \n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Define optimizer and LR Scheduler for training\n",
        "optimizer_ft = optim.SGD(vgg.parameters(), lr=0.001)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "IW9Ss-wxuu90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# F1 score calculating for image\n",
        "image_f1_data = {\n",
        "    0: {\n",
        "        \"true_positive\": 0.0,\n",
        "        \"false_positive\": 0.0,\n",
        "        \"false_negative\": 0.0\n",
        "    },\n",
        "    1: {\n",
        "        \"true_positive\": 0.0,\n",
        "        \"false_positive\": 0.0,\n",
        "        \"false_negative\": 0.0\n",
        "    },\n",
        "    2: {\n",
        "        \"true_positive\": 0.0,\n",
        "        \"false_positive\": 0.0,\n",
        "        \"false_negative\": 0.0\n",
        "    },\n",
        "    3: {\n",
        "        \"true_positive\": 0.0,\n",
        "        \"false_positive\": 0.0,\n",
        "        \"false_negative\": 0.0\n",
        "    }\n",
        "}\n",
        "\n",
        "def clear_image_f1_data():\n",
        "    for i in range(4):\n",
        "        image_f1_data[i][\"true_positive\"] = 0.0\n",
        "        image_f1_data[i][\"false_positive\"] = 0.0\n",
        "        image_f1_data[i][\"false_negative\"] = 0.0\n",
        "\n",
        "def update_image_f1_data(preditions: list, labels: list):\n",
        "    for i in range(len(preditions)):\n",
        "        if(preditions[i] == labels[i]):\n",
        "            image_f1_data[labels[i]][\"true_positive\"] += 1.0\n",
        "        else:\n",
        "            image_f1_data[labels[i]][\"false_positive\"] += 1.0\n",
        "            image_f1_data[preditions[i]][\"false_negative\"] += 1.0\n",
        "                \n",
        "\n",
        "def calculate_image_f1_for_class(class_number: int):\n",
        "    precision_divider = image_f1_data[class_number][\"true_positive\"]+image_f1_data[class_number][\"false_positive\"]\n",
        "    precision = (image_f1_data[class_number][\"true_positive\"] / precision_divider) if precision_divider > 0 else 0\n",
        "    recall_divider = image_f1_data[class_number][\"true_positive\"]+image_f1_data[class_number][\"false_negative\"]\n",
        "    recall = (image_f1_data[class_number][\"true_positive\"] / recall_divider) if recall_divider > 0 else 0\n",
        "    #print(f\"Precision: {precision} , Recall: {recall} \")\n",
        "    return (2 * (precision * recall) / (precision + recall)) if (precision + recall) > 0 else 0\n",
        "\n",
        "def calculate_image_macro_f1():\n",
        "    macro_f1 = 0.0\n",
        "    for i in range(4):\n",
        "        macro_f1 += calculate_image_f1_for_class(i)\n",
        "    return macro_f1/4"
      ],
      "metadata": {
        "id": "kU4rv8uUXgPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classes_convert(classes):\n",
        "  clas = []\n",
        "  for element in range(len(classes)):\n",
        "    var = classes[element]\n",
        "    for index in range(len(var)):\n",
        "      if var[index]==1:\n",
        "        clas.append(index)\n",
        "  return torch.tensor(clas)"
      ],
      "metadata": {
        "id": "vEeAe-_azz_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_checkpoint(model, optimizer, filename):\n",
        "    # Note: Input model & optimizer should be pre-defined.  This routine only updates their states.\n",
        "    if os.path.isfile(filename):\n",
        "        print(\"=> loading checkpoint '{}'\".format(filename))\n",
        "        checkpoint = torch.load(filename)\n",
        "        model.load_state_dict(checkpoint['state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "        print(\"=> loaded checkpoint '{}'\"\n",
        "                  .format(filename))\n",
        "    else:\n",
        "        print(\"=> no checkpoint found at '{}'\".format(filename))\n",
        "\n",
        "    return model, optimizer"
      ],
      "metadata": {
        "id": "E4mcdJkWeiiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining training model\n",
        "def train_model(vgg, criterion, optimizer, scheduler, num_epochs=1, debug=False):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      vgg (nn.Model): Neural Network model to traing\n",
        "      criterion (nn.LossFunction): Loss Function \n",
        "      optimizer (torch.optim): Optimalization Function\n",
        "      scheduler (torch.optim.lr_scheduler): Learning Rate Scheduler\n",
        "      num_epochs (int): Number of training epochs\n",
        "      debug (boolean): Debug mode toogle\n",
        "    \"\"\"\n",
        "\n",
        "    since = time.time()\n",
        "    best_model_wts = copy.deepcopy(vgg.state_dict())\n",
        "    best_acc = 0.0\n",
        "    avg_loss = 0\n",
        "    avg_acc = 0\n",
        "    avg_loss_val = 0\n",
        "    avg_acc_val = 0\n",
        "    \n",
        "    train_batches = len(dataloader)\n",
        "    val_batches = len(dataloader)\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        print(\"Epoch {}/{}\".format(epoch, num_epochs))\n",
        "        print('-' * 10)\n",
        "        \n",
        "        loss_train = 0\n",
        "        loss_val = 0\n",
        "        acc_train = 0\n",
        "        acc_val = 0\n",
        "        target_true = 0\n",
        "        predicted_true = 0\n",
        "        correct_true = 0\n",
        "        \n",
        "        vgg.train(True)\n",
        "        clear_image_f1_data()\n",
        "        for inputs, classes in iter(dataloader):\n",
        "            if use_gpu:\n",
        "                sample, clas = Variable(inputs.cuda()), Variable(classes.cuda())\n",
        "            else:\n",
        "                sample, clas = Variable(inputs), Variable(classes)\n",
        "            \n",
        "            # addressing batch labels to list\n",
        "            batch_labels = []\n",
        "            for row in clas.data:\n",
        "              for i in range(len(row)):\n",
        "                if row[i] == 1:\n",
        "                  batch_labels.append(i)\n",
        "            \n",
        "            if use_gpu:\n",
        "              batch_labels = torch.tensor(batch_labels).cuda()\n",
        "            else:\n",
        "              batch_labels = torch.tensor(batch_labels)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            outputs = vgg(sample)\n",
        "\n",
        "            if debug==True:\n",
        "              print(outputs)\n",
        "              print(clas)\n",
        "\n",
        "            _, preds = torch.max(outputs.data, -1)\n",
        "            loss = criterion(outputs, clas)\n",
        "            \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            update_image_f1_data(preds.squeeze().tolist(), batch_labels.squeeze().tolist())\n",
        "            \n",
        "            del sample, clas, outputs, preds\n",
        "            torch.cuda.empty_cache()\n",
        "        \n",
        "        epoch_train_macro_f1 = calculate_image_macro_f1()\n",
        "        \n",
        "        vgg.train(False)\n",
        "        vgg.eval()\n",
        "        clear_image_f1_data()    \n",
        "        for inputs, classes in iter(dataloader):\n",
        "            if use_gpu:\n",
        "                inputs, labels = Variable(inputs.cuda()), Variable(classes.cuda())\n",
        "            else:\n",
        "                inputs, labels = Variable(inputs), Variable(classes)\n",
        "\n",
        "            # addressing batch labels to list\n",
        "            batch_labels = []\n",
        "            for row in labels.data:\n",
        "              for i in range(len(row)):\n",
        "                if row[i] == 1:\n",
        "                  batch_labels.append(i)\n",
        "            \n",
        "            if use_gpu:\n",
        "              batch_labels = torch.tensor(batch_labels).cuda()\n",
        "            else:\n",
        "              batch_labels = torch.tensor(batch_labels)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            outputs = vgg(inputs)\n",
        "            \n",
        "            # Prediction\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            if debug==True:\n",
        "              print(\"Preds: \",preds)\n",
        "            loss = criterion(outputs, labels)\n",
        "            if debug==True:\n",
        "              print(\"[1]Classes shape: \",classes.shape)\n",
        "              print(\"[1]Classes: \",classes)\n",
        "\n",
        "            classes = classes_convert(classes)\n",
        "            if debug==True:\n",
        "              print(\"[2]Classes: \",classes.shape)\n",
        "              print(\"[2]Classes: \",classes)\n",
        "            \n",
        "            update_image_f1_data(preds.squeeze().tolist(), batch_labels.squeeze().tolist())\n",
        "            del inputs, labels, outputs, preds\n",
        "            torch.cuda.empty_cache()\n",
        "        \n",
        "        epoch_val_macro_f1 = calculate_image_macro_f1()\n",
        "\n",
        "        print()\n",
        "        print(\"Epoch {} result: \".format(epoch))\n",
        "        print(\"F1 score: {:.4f} (train), {:.4f} (val)\".format(epoch_train_macro_f1, epoch_val_macro_f1))\n",
        "        print('-' * 10)\n",
        "        print()\n",
        "        \n",
        "        if avg_acc_val > best_acc:\n",
        "            best_acc = avg_acc_val\n",
        "            best_model_wts = copy.deepcopy(vgg.state_dict())\n",
        "        \n",
        "    elapsed_time = time.time() - since\n",
        "    print()\n",
        "    print(\"Training completed in {:.0f}m {:.0f}s\".format(elapsed_time // 60, elapsed_time % 60))\n",
        "    print(\"Best acc: {:.4f}\".format(best_acc))\n",
        "    \n",
        "    vgg.load_state_dict(best_model_wts)\n",
        "    return vgg"
      ],
      "metadata": {
        "id": "d_glLctDu338"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if use_trained_model==False and image_model_continue_training == False:\n",
        "  vgg = train_model(vgg, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=image_epochs, debug=False)\n",
        "  if save_model:\n",
        "    torch.save(vgg.state_dict(), image_save_model_path)\n",
        "    print(\"Image model saved\")\n",
        "    checkpoint = {'state_dict': vgg.state_dict(), 'optimizer': optimizer_ft.state_dict()}\n",
        "    torch.save(checkpoint, image_checkpoint_path)\n",
        "    print(\"Checkpoint saved\")\n",
        "\n",
        "elif image_model_continue_training == True:\n",
        "  \n",
        "  checkpoint_model, optimizer = load_checkpoint(vgg, optimizer_ft,image_checkpoint_path)\n",
        "  checkpoint_model = checkpoint_model.cuda()\n",
        "  lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "  for state in optimizer.state.values():\n",
        "    for k,v in state.items():\n",
        "      if isinstance(v, torch.Tensor):\n",
        "        state[k] = v.cuda()\n",
        "        \n",
        "  vgg = train_model(checkpoint_model, criterion, optimizer, lr_scheduler, num_epochs=image_epochs, debug=False)\n",
        "  if save_model:\n",
        "    torch.save(vgg.state_dict(), image_save_model_path)\n",
        "    print(\"Image model saved\")\n",
        "    checkpoint = {'state_dict': vgg.state_dict(), 'optimizer': optimizer.state_dict()}\n",
        "    torch.save(checkpoint, image_checkpoint_path)\n",
        "    print(\"Checkpoint saved\")\n",
        "    "
      ],
      "metadata": {
        "id": "8V6CUYAQu6A6",
        "outputId": "9465a4e6-4458-4356-f205-a7966c154e9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 0 result: \n",
            "F1 score: 0.2106 (train), 0.2088 (val)\n",
            "----------\n",
            "\n",
            "Epoch 1/25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gałąź przekształcania tekstu"
      ],
      "metadata": {
        "id": "63L0we3L_NCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_f1_data = {\n",
        "    0: {\n",
        "        \"true_positive\": 0.0,\n",
        "        \"false_positive\": 0.0,\n",
        "        \"false_negative\": 0.0\n",
        "    },\n",
        "    1: {\n",
        "        \"true_positive\": 0.0,\n",
        "        \"false_positive\": 0.0,\n",
        "        \"false_negative\": 0.0\n",
        "    },\n",
        "    2: {\n",
        "        \"true_positive\": 0.0,\n",
        "        \"false_positive\": 0.0,\n",
        "        \"false_negative\": 0.0\n",
        "    },\n",
        "    3: {\n",
        "        \"true_positive\": 0.0,\n",
        "        \"false_positive\": 0.0,\n",
        "        \"false_negative\": 0.0\n",
        "    }\n",
        "}\n",
        "\n",
        "def clear_text_f1_data():\n",
        "    for i in range(4):\n",
        "        text_f1_data[i][\"true_positive\"] = 0.0\n",
        "        text_f1_data[i][\"false_positive\"] = 0.0\n",
        "        text_f1_data[i][\"false_negative\"] = 0.0\n",
        "\n",
        "def update_text_f1_data(preditions: list, labels: list):\n",
        "    if type(preditions) is int:\n",
        "      preditions = [preditions]\n",
        "    if type(labels) is int:\n",
        "      labels = [labels]\n",
        "    for i in range(min(len(preditions), len(labels))):\n",
        "        if(preditions[i] == labels[i]):\n",
        "            text_f1_data[labels[i]][\"true_positive\"] += 1.0\n",
        "        else:\n",
        "            text_f1_data[labels[i]][\"false_positive\"] += 1.0\n",
        "            text_f1_data[preditions[i]][\"false_negative\"] += 1.0\n",
        "                \n",
        "\n",
        "def calculate_text_f1_for_class(class_number: int):\n",
        "    if text_f1_data[class_number][\"true_positive\"] == 0:\n",
        "      return 0\n",
        "    precision = text_f1_data[class_number][\"true_positive\"] / (text_f1_data[class_number][\"true_positive\"]+text_f1_data[class_number][\"false_positive\"])\n",
        "    recall = text_f1_data[class_number][\"true_positive\"] / (text_f1_data[class_number][\"true_positive\"]+text_f1_data[class_number][\"false_negative\"])\n",
        "    # print(f\"Precision: {precision} , Recall: {recall} \")\n",
        "    return 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "def calculate_text_macro_f1():\n",
        "    macro_f1 = 0.0\n",
        "    for i in range(4):\n",
        "        macro_f1 += calculate_text_f1_for_class(i)\n",
        "    return macro_f1/4"
      ],
      "metadata": {
        "id": "qgTTp_11Xc7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_classes_convert(classes):\n",
        "  y = classes\n",
        "  # Actual conversion using y elements as index \n",
        "  M = np.zeros(len(y))\n",
        "\n",
        "  for i in range(len(y)):\n",
        "    M[i]=torch.argmax(y[i])\n",
        "  return torch.tensor(M)"
      ],
      "metadata": {
        "id": "8HoqPaoUYVj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BERT"
      ],
      "metadata": {
        "id": "RM1e5Ww0_cNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BertDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "        self.labels = [np.argmax(l) for l in df['label']]\n",
        "        self.data = [self.tokenizer(t, \n",
        "                            padding=\"max_length\", max_length=128,\n",
        "                            truncation=True, return_tensors=\"pt\") for t in df['text']]\n",
        "\n",
        "    def classes(self):\n",
        "        return self.labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def get_batch_labels(self, idx):\n",
        "        # Fetch a batch of labels\n",
        "        return np.array(self.labels[idx])\n",
        "\n",
        "    def get_batch_texts(self, idx):\n",
        "        # Fetch a batch of inputs\n",
        "        return self.data[idx]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        batch_texts = self.get_batch_texts(idx)\n",
        "        batch_y = self.get_batch_labels(idx)\n",
        "\n",
        "        return batch_texts, batch_y"
      ],
      "metadata": {
        "id": "TeX0OrYcc7tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42), \n",
        "                                     [int(.8*len(df)), int(.9*len(df))])\n",
        "\n",
        "print(len(df_train),len(df_val), len(df_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ey4v9TE_dczE",
        "outputId": "03e46bef-daf7-496d-87fd-78fca1162ef6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5585 698 699\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BertClassifier(nn.Module):\n",
        "    def __init__(self, dropout=0.5):\n",
        "        super(BertClassifier, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(768, 4)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, input_id, mask):\n",
        "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(dropout_output)\n",
        "        final_layer = self.relu(linear_output)\n",
        "\n",
        "        return final_layer"
      ],
      "metadata": {
        "id": "1Ik7CuJfeIu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text model train - BERT\n",
        "\n",
        "def train_bert(model, train_data, val_data, lr, epochs):\n",
        "    train, val = BertDataset(train_data), BertDataset(val_data)\n",
        "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
        "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = Adam(model.parameters(), lr = lr)\n",
        "    \n",
        "    if use_cuda:\n",
        "            model = model.cuda()\n",
        "            criterion = criterion.cuda()\n",
        "\n",
        "    for epoch_num in range(epochs):\n",
        "            total_acc_train = 0\n",
        "            total_loss_train = 0\n",
        "            clear_text_f1_data()\n",
        "            for train_input, train_label in tqdm(train_dataloader):\n",
        "\n",
        "                train_label = train_label.to(device)\n",
        "                mask = train_input['attention_mask'].to(device)\n",
        "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                output = model(input_id, mask)\n",
        "                \n",
        "                batch_loss = criterion(output, train_label)\n",
        "                total_loss_train += batch_loss.item()\n",
        "                \n",
        "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
        "                total_acc_train += acc\n",
        "                update_text_f1_data(output.argmax(dim=1).tolist(), train_label.squeeze().tolist())\n",
        "                model.zero_grad()\n",
        "                batch_loss.backward()\n",
        "                optimizer.step()\n",
        "            \n",
        "            total_acc_val = 0\n",
        "            total_loss_val = 0\n",
        "            epoch_train_macro_f1 = calculate_text_macro_f1()\n",
        "            clear_text_f1_data()\n",
        "            with torch.no_grad():\n",
        "\n",
        "                for val_input, val_label in val_dataloader:\n",
        "\n",
        "                    val_label = val_label.to(device)\n",
        "                    mask = val_input['attention_mask'].to(device)\n",
        "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                    output = model(input_id, mask)\n",
        "\n",
        "                    batch_loss = criterion(output, val_label)\n",
        "                    total_loss_val += batch_loss.item()\n",
        "                    \n",
        "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
        "                    update_text_f1_data(output.argmax(dim=1).tolist(), val_label.squeeze().tolist())\n",
        "                    total_acc_val += acc\n",
        "            epoch_val_macro_f1 = calculate_text_macro_f1()\n",
        "            print(\n",
        "                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n",
        "                | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
        "                | Val Loss: {total_loss_val / len(val_data): .3f} \\\n",
        "                | Val Accuracy: {total_acc_val / len(val_data): .3f} \\\n",
        "                | Train macro F1: {epoch_train_macro_f1} \\\n",
        "                | Val macro F1: {epoch_val_macro_f1} \\\n",
        "            ')\n",
        "            if save_model:\n",
        "                torch.save(model.state_dict(), text_save_model_path)\n",
        "                print(\"Image model saved\")\n",
        "                checkpoint = {'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict()}\n",
        "                torch.save(checkpoint, text_checkpoint_path)\n",
        "                print(\"Checkpoint saved\")\n",
        "\n",
        "def evaluate_bert(model, test_data):\n",
        "\n",
        "    test = BertDataset(test_data)\n",
        "\n",
        "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    if use_cuda:\n",
        "\n",
        "        model = model.cuda()\n",
        "\n",
        "    total_acc_test = 0\n",
        "    clear_text_f1_data()\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for test_input, test_label in test_dataloader:\n",
        "\n",
        "              test_label = test_label.to(device)\n",
        "              mask = test_input['attention_mask'].to(device)\n",
        "              input_id = test_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "              output = model(input_id, mask)\n",
        "\n",
        "              acc = (output.argmax(dim=1) == test_label).sum().item()\n",
        "              total_acc_test += acc\n",
        "              update_text_f1_data(output.argmax(dim=1).tolist(), test_label.squeeze().tolist())\n",
        "    \n",
        "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')\n",
        "    print(\"F1 score: {:.4f}\".format(calculate_text_macro_f1()))"
      ],
      "metadata": {
        "id": "xhc7s-Xid2Ta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "bert_model = BertClassifier()\n",
        "LR = 1e-6\n",
        "              \n",
        "train_bert(bert_model, df_train, df_val, LR, EPOCHS)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kZx8aIJBfMYQ",
        "outputId": "15691294-e1fe-42c7-c728-25bab539aeac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "100%|██████████| 2793/2793 [08:12<00:00,  5.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 1 | Train Loss:  0.701                 | Train Accuracy:  0.266                 | Val Loss:  0.695                 | Val Accuracy:  0.274                 | Train macro F1: 0.22642321870222237                 | Val macro F1: 0.21793405839022026             \n",
            "Image model saved\n",
            "Checkpoint saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2793/2793 [08:11<00:00,  5.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 2 | Train Loss:  0.693                 | Train Accuracy:  0.286                 | Val Loss:  0.692                 | Val Accuracy:  0.266                 | Train macro F1: 0.22151699539199585                 | Val macro F1: 0.18966669401233238             \n",
            "Image model saved\n",
            "Checkpoint saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2793/2793 [08:11<00:00,  5.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 3 | Train Loss:  0.690                 | Train Accuracy:  0.290                 | Val Loss:  0.696                 | Val Accuracy:  0.268                 | Train macro F1: 0.20890920007155364                 | Val macro F1: 0.19086582916261127             \n",
            "Image model saved\n",
            "Checkpoint saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2793/2793 [08:11<00:00,  5.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 4 | Train Loss:  0.687                 | Train Accuracy:  0.309                 | Val Loss:  0.696                 | Val Accuracy:  0.261                 | Train macro F1: 0.21055995444925746                 | Val macro F1: 0.17678909921620986             \n",
            "Image model saved\n",
            "Checkpoint saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2793/2793 [08:12<00:00,  5.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 5 | Train Loss:  0.681                 | Train Accuracy:  0.327                 | Val Loss:  0.701                 | Val Accuracy:  0.259                 | Train macro F1: 0.21994316162135963                 | Val macro F1: 0.18619628800462193             \n",
            "Image model saved\n",
            "Checkpoint saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2793/2793 [08:12<00:00,  5.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 6 | Train Loss:  0.663                 | Train Accuracy:  0.370                 | Val Loss:  0.707                 | Val Accuracy:  0.269                 | Train macro F1: 0.2504049458059677                 | Val macro F1: 0.1809476472077275             \n",
            "Image model saved\n",
            "Checkpoint saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2793/2793 [08:12<00:00,  5.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 7 | Train Loss:  0.637                 | Train Accuracy:  0.420                 | Val Loss:  0.732                 | Val Accuracy:  0.281                 | Train macro F1: 0.2880085646834268                 | Val macro F1: 0.1860989580107227             \n",
            "Image model saved\n",
            "Checkpoint saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2793/2793 [08:12<00:00,  5.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 8 | Train Loss:  0.595                 | Train Accuracy:  0.478                 | Val Loss:  0.747                 | Val Accuracy:  0.249                 | Train macro F1: 0.3320079344370384                 | Val macro F1: 0.17651695558656455             \n",
            "Image model saved\n",
            "Checkpoint saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2793/2793 [08:12<00:00,  5.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 9 | Train Loss:  0.548                 | Train Accuracy:  0.528                 | Val Loss:  0.769                 | Val Accuracy:  0.282                 | Train macro F1: 0.38462606477692                 | Val macro F1: 0.22262964268656038             \n",
            "Image model saved\n",
            "Checkpoint saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2793/2793 [08:12<00:00,  5.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 10 | Train Loss:  0.490                 | Train Accuracy:  0.605                 | Val Loss:  0.788                 | Val Accuracy:  0.271                 | Train macro F1: 0.47605540746798686                 | Val macro F1: 0.21980384855839952             \n",
            "Image model saved\n",
            "Checkpoint saved\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-c55f80d126ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_bert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mevaluate_bert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-31-8aac73f425cf>\u001b[0m in \u001b[0;36mevaluate_bert\u001b[0;34m(model, test_data)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_bert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mtest_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'fields'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_bert(bert_model, df_test)"
      ],
      "metadata": {
        "id": "dpEshY9vmvHJ",
        "outputId": "ad857e3f-21e9-4ef4-90a8-4f8a9f3756f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy:  0.280\n",
            "F1 score: 0.2279\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM"
      ],
      "metadata": {
        "id": "5ycjOcf8_jMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if use_trained_model==False:\n",
        "\n",
        "class ModelParam(object):\n",
        "    def __init__(self, param_dict: dict = dict()):\n",
        "        self.input_size = param_dict.get('input_size', 0)\n",
        "        self.vocab_size = param_dict.get('vocab_size')\n",
        "        self.embedding_dim = param_dict.get('embedding_dim', 100)\n",
        "        self.target_dim = param_dict.get('target_dim')\n",
        "        \n",
        "class TextModel(nn.Module):\n",
        "    def __init__(self, model_param: ModelParam):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(model_param.vocab_size, model_param.embedding_dim)\n",
        "        self.conv = nn.Conv1d(64, 100, 4)\n",
        "        self.max_pool = nn.MaxPool1d(2)\n",
        "        self.lstm = nn.LSTM(48, 16, bidirectional=True, batch_first=True)\n",
        "        self.fc = nn.Linear(in_features=3200, out_features=4, bias=True)\n",
        "        self.sigm = nn.Sigmoid()\n",
        "        self.flatt = nn.Flatten()\n",
        "        # self.bert = BertModel.from_pretrained('bert-base-cased')\n",
        "        # self.tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.embedding(x)\n",
        "        features = F.relu(features)\n",
        "        # print(features.shape)\n",
        "        features = self.conv(features)\n",
        "        # print(features.shape)\n",
        "        features = self.max_pool(features)\n",
        "        # print(features.shape)\n",
        "        features, hidden = self.lstm(features)\n",
        "        # print(features.shape)\n",
        "        features = self.flatt(features)\n",
        "        features = self.fc(features)\n",
        "        features = self.sigm(features)\n",
        "        return features"
      ],
      "metadata": {
        "id": "BFVgxQBzX7Fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text model train - LSTM\n",
        "\n",
        "if use_trained_model==False:\n",
        "    model_param = ModelParam(\n",
        "    param_dict=dict(\n",
        "        vocab_size=len(text_field.vocab),\n",
        "        input_size=64,\n",
        "        embedding_dim=100,\n",
        "        target_dim=4\n",
        "        )\n",
        "    )\n",
        "    train_text_model = TextModel(model_param).cuda()\n",
        "    \n",
        "    loss_function = nn.BCELoss()\n",
        "    optimizer = optim.Adam(train_text_model.parameters(), lr=0.0002)\n",
        "    best_model_wts = copy.deepcopy(train_text_model.state_dict())\n",
        "    best_val_f1 = -1\n",
        "    epoch_count = 0\n",
        "    losses = []\n",
        "    val_losses = []\n",
        "    val_acc = []\n",
        "    for epoch in range(text_epochs):\n",
        "        train_text_model.train()\n",
        "        clear_text_f1_data()\n",
        "        b_num = 0\n",
        "        epoch_num = 0\n",
        "        epoch_losses = []\n",
        "        k = 0\n",
        "        for batch in train_iter:\n",
        "            optimizer.zero_grad()\n",
        "            prediction = train_text_model(batch.text.T.cuda())\n",
        "            batch_label = batch.label.to(torch.float)\n",
        "            labels = text_classes_convert(batch_label).cuda()\n",
        "            preds = torch.flatten(torch.max(prediction, 1)[1]).float().cuda()\n",
        "            # print(prediction.shape)\n",
        "            # print(batch.label.shape)\n",
        "            loss = loss_function(torch.squeeze(prediction), torch.squeeze(batch.label.to(torch.float)).cuda())\n",
        "            #update_text_f1_data(preds.squeeze().tolist(), labels.squeeze().tolist())\n",
        "            # print(prediction)\n",
        "            # print(batch.label)\n",
        "            # print(preds)\n",
        "            # print(labels)\n",
        "            update_text_f1_data(preds.tolist(), labels.tolist())\n",
        "            loss.backward()\n",
        "            epoch_losses.append(loss.item())\n",
        "            optimizer.step()\n",
        "            k = k+1\n",
        "        \n",
        "        losses.append(sum(epoch_losses)/k)\n",
        "        train_text_macro_f1 = calculate_text_macro_f1()\n",
        "        \n",
        "        train_text_model.eval()\n",
        "        clear_text_f1_data()\n",
        "        val_epoch_losses = []\n",
        "        k = 0\n",
        "        total_acc_val = 0\n",
        "        \n",
        "        test_iter_elements_number = 0\n",
        "        for batch in test_iter:\n",
        "            with torch.no_grad():\n",
        "                optimizer.zero_grad()\n",
        "                prediction = train_text_model(batch.text.T.cuda())\n",
        "                batch.label = batch.label.to(torch.float)\n",
        "                labels = text_classes_convert(batch.label).cuda()\n",
        "                # preds = torch.flatten(torch.max(prediction, 1)[1]).float().cuda()\n",
        "                _, preds = torch.max(prediction, 1)\n",
        "                # print(preds)\n",
        "                # print(preds2)\n",
        "                loss = loss_function(torch.squeeze(prediction), torch.squeeze(batch.label.to(torch.float)).cuda())\n",
        "                #update_text_f1_data(preds.squeeze().tolist(), labels.squeeze().tolist())\n",
        "                # print(prediction)\n",
        "                # print(batch.label)\n",
        "                # print(preds)\n",
        "                # print(labels)\n",
        "                \n",
        "                test_iter_elements_number += len(labels)\n",
        "                acc = (preds == labels).sum().item()\n",
        "                # print(acc)\n",
        "                # print(loss)\n",
        "                total_acc_val += acc\n",
        "                val_epoch_losses.append(loss.item())\n",
        "                update_text_f1_data(preds.tolist(), labels.tolist())\n",
        "                k = k+1\n",
        "\n",
        "        # print(total_acc_val)\n",
        "        # print(test_iter_elements_number)\n",
        "        val_acc.append(total_acc_val / test_iter_elements_number)\n",
        "        val_losses.append(sum(val_epoch_losses)/k)\n",
        "        val_text_macro_f1 = calculate_text_macro_f1()\n",
        "        if val_text_macro_f1 > best_val_f1:\n",
        "            best_val_f1 = val_text_macro_f1\n",
        "            best_model_wts = copy.deepcopy(train_text_model.state_dict())\n",
        "        else :\n",
        "            train_text_model.load_state_dict(best_model_wts)\n",
        "        print()\n",
        "        print(\"Epoch {} result: \".format(epoch))\n",
        "        print(\"F1 score: {:.4f} (train), {:.4f} (val)\".format(train_text_macro_f1, val_text_macro_f1))\n",
        "        print('-' * 10)\n",
        "        print()\n",
        "    print(f\"Best val f1 score: {best_val_f1}\")\n",
        "    if save_model:\n",
        "        torch.save(best_model_wts, text_save_model_path)\n",
        "        print(\"Text model saved\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yjVN5puCYh1G",
        "outputId": "ab3e2c67-297c-4336-87f2-eb9d682e58de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 0 result: \n",
            "F1 score: 0.1497 (train), 0.1508 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 1 result: \n",
            "F1 score: 0.1845 (train), 0.1748 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 2 result: \n",
            "F1 score: 0.1349 (train), 0.2253 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 3 result: \n",
            "F1 score: 0.1418 (train), 0.2339 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 4 result: \n",
            "F1 score: 0.1731 (train), 0.0092 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 5 result: \n",
            "F1 score: 0.1782 (train), 0.1660 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 6 result: \n",
            "F1 score: 0.1681 (train), 0.2444 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 7 result: \n",
            "F1 score: 0.1389 (train), 0.2435 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 8 result: \n",
            "F1 score: 0.1431 (train), 0.0083 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 9 result: \n",
            "F1 score: 0.1384 (train), 0.0180 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 10 result: \n",
            "F1 score: 0.1519 (train), 0.0135 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 11 result: \n",
            "F1 score: 0.1424 (train), 0.0209 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 12 result: \n",
            "F1 score: 0.1422 (train), 0.0000 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 13 result: \n",
            "F1 score: 0.1510 (train), 0.2189 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 14 result: \n",
            "F1 score: 0.1483 (train), 0.0280 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 15 result: \n",
            "F1 score: 0.1458 (train), 0.1641 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 16 result: \n",
            "F1 score: 0.1470 (train), 0.0237 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 17 result: \n",
            "F1 score: 0.1384 (train), 0.1741 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 18 result: \n",
            "F1 score: 0.1323 (train), 0.0300 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 19 result: \n",
            "F1 score: 0.1598 (train), 0.0028 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 20 result: \n",
            "F1 score: 0.1389 (train), 0.2184 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 21 result: \n",
            "F1 score: 0.1389 (train), 0.0295 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 22 result: \n",
            "F1 score: 0.1304 (train), 0.0000 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 23 result: \n",
            "F1 score: 0.1419 (train), 0.1889 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 24 result: \n",
            "F1 score: 0.1400 (train), 0.1116 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 25 result: \n",
            "F1 score: 0.1407 (train), 0.2273 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 26 result: \n",
            "F1 score: 0.1510 (train), 0.0098 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 27 result: \n",
            "F1 score: 0.1574 (train), 0.0082 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 28 result: \n",
            "F1 score: 0.1497 (train), 0.0000 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 29 result: \n",
            "F1 score: 0.1685 (train), 0.0000 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 30 result: \n",
            "F1 score: 0.1276 (train), 0.1501 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 31 result: \n",
            "F1 score: 0.1322 (train), 0.0000 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 32 result: \n",
            "F1 score: 0.1408 (train), 0.0202 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 33 result: \n",
            "F1 score: 0.1655 (train), 0.0294 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 34 result: \n",
            "F1 score: 0.1323 (train), 0.1318 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 35 result: \n",
            "F1 score: 0.1351 (train), 0.2436 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 36 result: \n",
            "F1 score: 0.1386 (train), 0.0000 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 37 result: \n",
            "F1 score: 0.1433 (train), 0.1662 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 38 result: \n",
            "F1 score: 0.1294 (train), 0.2314 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 39 result: \n",
            "F1 score: 0.1504 (train), 0.0000 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 40 result: \n",
            "F1 score: 0.1538 (train), 0.0000 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 41 result: \n",
            "F1 score: 0.1551 (train), 0.1663 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 42 result: \n",
            "F1 score: 0.1313 (train), 0.2227 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 43 result: \n",
            "F1 score: 0.1312 (train), 0.1240 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 44 result: \n",
            "F1 score: 0.1343 (train), 0.1579 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 45 result: \n",
            "F1 score: 0.1353 (train), 0.0000 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 46 result: \n",
            "F1 score: 0.1339 (train), 0.1610 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 47 result: \n",
            "F1 score: 0.1325 (train), 0.1612 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 48 result: \n",
            "F1 score: 0.1401 (train), 0.1860 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 49 result: \n",
            "F1 score: 0.1352 (train), 0.2300 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 50 result: \n",
            "F1 score: 0.1441 (train), 0.1659 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 51 result: \n",
            "F1 score: 0.1380 (train), 0.0200 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 52 result: \n",
            "F1 score: 0.1468 (train), 0.0171 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 53 result: \n",
            "F1 score: 0.1422 (train), 0.1556 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 54 result: \n",
            "F1 score: 0.1441 (train), 0.1624 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 55 result: \n",
            "F1 score: 0.1614 (train), 0.0010 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 56 result: \n",
            "F1 score: 0.1384 (train), 0.1728 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 57 result: \n",
            "F1 score: 0.1456 (train), 0.0000 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 58 result: \n",
            "F1 score: 0.1414 (train), 0.0510 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 59 result: \n",
            "F1 score: 0.1434 (train), 0.0000 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 60 result: \n",
            "F1 score: 0.1427 (train), 0.1655 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 61 result: \n",
            "F1 score: 0.1391 (train), 0.2451 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 62 result: \n",
            "F1 score: 0.1489 (train), 0.2462 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 63 result: \n",
            "F1 score: 0.1446 (train), 0.0194 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 64 result: \n",
            "F1 score: 0.1509 (train), 0.0000 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 65 result: \n",
            "F1 score: 0.1426 (train), 0.1647 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 66 result: \n",
            "F1 score: 0.1392 (train), 0.0126 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 67 result: \n",
            "F1 score: 0.1311 (train), 0.0000 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 68 result: \n",
            "F1 score: 0.1378 (train), 0.2416 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 69 result: \n",
            "F1 score: 0.1448 (train), 0.0000 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 70 result: \n",
            "F1 score: 0.1300 (train), 0.0696 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 71 result: \n",
            "F1 score: 0.1501 (train), 0.1657 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 72 result: \n",
            "F1 score: 0.1410 (train), 0.1633 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 73 result: \n",
            "F1 score: 0.1458 (train), 0.1864 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 74 result: \n",
            "F1 score: 0.1315 (train), 0.1574 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 75 result: \n",
            "F1 score: 0.1402 (train), 0.0000 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 76 result: \n",
            "F1 score: 0.1406 (train), 0.1648 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 77 result: \n",
            "F1 score: 0.1387 (train), 0.2349 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 78 result: \n",
            "F1 score: 0.1306 (train), 0.0000 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 79 result: \n",
            "F1 score: 0.1370 (train), 0.0287 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 80 result: \n",
            "F1 score: 0.1362 (train), 0.1865 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 81 result: \n",
            "F1 score: 0.1525 (train), 0.0186 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 82 result: \n",
            "F1 score: 0.1352 (train), 0.0656 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 83 result: \n",
            "F1 score: 0.1516 (train), 0.0193 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 84 result: \n",
            "F1 score: 0.1425 (train), 0.2472 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 85 result: \n",
            "F1 score: 0.1510 (train), 0.0000 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 86 result: \n",
            "F1 score: 0.1419 (train), 0.0000 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 87 result: \n",
            "F1 score: 0.1385 (train), 0.0257 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 88 result: \n",
            "F1 score: 0.1392 (train), 0.2438 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 89 result: \n",
            "F1 score: 0.1331 (train), 0.0185 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 90 result: \n",
            "F1 score: 0.1521 (train), 0.1657 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 91 result: \n",
            "F1 score: 0.1405 (train), 0.1658 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 92 result: \n",
            "F1 score: 0.1449 (train), 0.0119 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 93 result: \n",
            "F1 score: 0.1378 (train), 0.2459 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 94 result: \n",
            "F1 score: 0.1395 (train), 0.1630 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 95 result: \n",
            "F1 score: 0.1503 (train), 0.0000 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 96 result: \n",
            "F1 score: 0.1385 (train), 0.1802 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 97 result: \n",
            "F1 score: 0.1318 (train), 0.0706 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 98 result: \n",
            "F1 score: 0.1471 (train), 0.0195 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 99 result: \n",
            "F1 score: 0.1523 (train), 0.1666 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 100 result: \n",
            "F1 score: 0.1383 (train), 0.1614 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 101 result: \n",
            "F1 score: 0.1278 (train), 0.1578 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 102 result: \n",
            "F1 score: 0.1297 (train), 0.0531 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 103 result: \n",
            "F1 score: 0.1511 (train), 0.0000 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 104 result: \n",
            "F1 score: 0.1448 (train), 0.1887 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 105 result: \n",
            "F1 score: 0.1500 (train), 0.0118 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 106 result: \n",
            "F1 score: 0.1407 (train), 0.0109 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 107 result: \n",
            "F1 score: 0.1510 (train), 0.0074 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 108 result: \n",
            "F1 score: 0.1443 (train), 0.0083 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 109 result: \n",
            "F1 score: 0.1410 (train), 0.0028 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 110 result: \n",
            "F1 score: 0.1350 (train), 0.0000 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 111 result: \n",
            "F1 score: 0.1308 (train), 0.1545 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 112 result: \n",
            "F1 score: 0.1367 (train), 0.0000 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 113 result: \n",
            "F1 score: 0.1446 (train), 0.1633 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 114 result: \n",
            "F1 score: 0.1361 (train), 0.0441 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 115 result: \n",
            "F1 score: 0.1351 (train), 0.1629 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 116 result: \n",
            "F1 score: 0.1384 (train), 0.2475 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 117 result: \n",
            "F1 score: 0.1595 (train), 0.0000 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 118 result: \n",
            "F1 score: 0.1382 (train), 0.0000 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 119 result: \n",
            "F1 score: 0.1449 (train), 0.0000 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 120 result: \n",
            "F1 score: 0.1371 (train), 0.0344 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 121 result: \n",
            "F1 score: 0.1335 (train), 0.2074 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 122 result: \n",
            "F1 score: 0.1418 (train), 0.0000 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 123 result: \n",
            "F1 score: 0.1332 (train), 0.1608 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 124 result: \n",
            "F1 score: 0.1306 (train), 0.1537 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 125 result: \n",
            "F1 score: 0.1374 (train), 0.0264 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 126 result: \n",
            "F1 score: 0.1447 (train), 0.1637 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 127 result: \n",
            "F1 score: 0.1441 (train), 0.0101 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 128 result: \n",
            "F1 score: 0.1550 (train), 0.1767 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 129 result: \n",
            "F1 score: 0.1452 (train), 0.1656 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 130 result: \n",
            "F1 score: 0.1541 (train), 0.0019 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 131 result: \n",
            "F1 score: 0.1549 (train), 0.1693 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 132 result: \n",
            "F1 score: 0.1431 (train), 0.1797 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 133 result: \n",
            "F1 score: 0.1412 (train), 0.0000 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 134 result: \n",
            "F1 score: 0.1454 (train), 0.0101 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 135 result: \n",
            "F1 score: 0.1373 (train), 0.1797 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 136 result: \n",
            "F1 score: 0.1375 (train), 0.1908 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 137 result: \n",
            "F1 score: 0.1394 (train), 0.1844 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 138 result: \n",
            "F1 score: 0.1486 (train), 0.0083 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 139 result: \n",
            "F1 score: 0.1387 (train), 0.0000 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 140 result: \n",
            "F1 score: 0.1535 (train), 0.1663 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 141 result: \n",
            "F1 score: 0.1358 (train), 0.1909 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 142 result: \n",
            "F1 score: 0.1422 (train), 0.0000 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 143 result: \n",
            "F1 score: 0.1516 (train), 0.0074 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 144 result: \n",
            "F1 score: 0.1472 (train), 0.0000 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 145 result: \n",
            "F1 score: 0.1426 (train), 0.0000 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 146 result: \n",
            "F1 score: 0.1561 (train), 0.0056 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 147 result: \n",
            "F1 score: 0.1337 (train), 0.0718 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 148 result: \n",
            "F1 score: 0.1365 (train), 0.0262 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 149 result: \n",
            "F1 score: 0.1318 (train), 0.1970 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 150 result: \n",
            "F1 score: 0.1468 (train), 0.1650 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 151 result: \n",
            "F1 score: 0.1405 (train), 0.0375 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 152 result: \n",
            "F1 score: 0.1390 (train), 0.0551 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 153 result: \n",
            "F1 score: 0.1496 (train), 0.1940 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 154 result: \n",
            "F1 score: 0.1341 (train), 0.1629 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 155 result: \n",
            "F1 score: 0.1338 (train), 0.0309 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 156 result: \n",
            "F1 score: 0.1392 (train), 0.1622 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 157 result: \n",
            "F1 score: 0.1493 (train), 0.0019 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 158 result: \n",
            "F1 score: 0.1467 (train), 0.0000 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 159 result: \n",
            "F1 score: 0.1371 (train), 0.0000 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 160 result: \n",
            "F1 score: 0.1350 (train), 0.0634 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 161 result: \n",
            "F1 score: 0.1422 (train), 0.2461 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 162 result: \n",
            "F1 score: 0.1337 (train), 0.1613 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 163 result: \n",
            "F1 score: 0.1370 (train), 0.1648 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 164 result: \n",
            "F1 score: 0.1427 (train), 0.1841 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 165 result: \n",
            "F1 score: 0.1406 (train), 0.0194 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 166 result: \n",
            "F1 score: 0.1387 (train), 0.1205 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Epoch 167 result: \n",
            "F1 score: 0.1362 (train), 0.0000 (val)\n",
            "----------\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-63a1e4ce4984>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0;31m#update_text_f1_data(preds.squeeze().tolist(), labels.squeeze().tolist())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                 \u001b[0mupdate_text_f1_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mval_text_macro_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_text_macro_f1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-4fe00f925a11>\u001b[0m in \u001b[0;36mupdate_text_f1_data\u001b[0;34m(preditions, labels)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mupdate_text_f1_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreditions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreditions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreditions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mtext_f1_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"true_positive\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'float' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testowanie wytrenowanych modeli"
      ],
      "metadata": {
        "id": "-KspV4xGLPv-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TestDataset(Dataset):\n",
        "    def __init__(self, csv_path, low_data_mode=False, debug=False):\n",
        "        self.debug = debug\n",
        "        # Read the csv_file\n",
        "        if low_data_mode==True:\n",
        "          self.data_info = pd.read_csv(csv_path, header = 6952)\n",
        "        else:\n",
        "          self.data_info = pd.read_csv(csv_path, header = 3)\n",
        "\n",
        "        # Column containing image names\n",
        "        self.image_arr = np.asarray(self.data_info.iloc[:, 1])\n",
        "        # Columns containing emotions classification\n",
        "        self.humour_arr = np.asarray(self.data_info.iloc[:, 4])\n",
        "        self.sarcasm_arr = np.asarray(self.data_info.iloc[:, 5])\n",
        "        self.offensive_arr = np.asarray(self.data_info.iloc[:, 6])\n",
        "        self.motivational_arr = np.asarray(self.data_info.iloc[:, 7])\n",
        "        \n",
        "        # Transforms performed on loaded image\n",
        "        self.data_transforms = transforms.Compose([\n",
        "                                      transforms.Resize((224, 224)),\n",
        "                                      transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "        \n",
        "        # Array with class vectors for each image\n",
        "        self.labels = []\n",
        "        self.text_arr = self.data_info.iloc[:, 3]\n",
        "        raw_df = []\n",
        "\n",
        "        for i in range(len(self.text_arr)):\n",
        "            raw_df.append([str(self.text_arr[i])])\n",
        "        self.df = pd.DataFrame(raw_df[:-2], columns=['text'])\n",
        "\n",
        "        self.text_field = Field(\n",
        "            sequential=True,\n",
        "            tokenize='basic_english', \n",
        "            fix_length=50, \n",
        "            lower=True\n",
        "        )\n",
        "        # prepocess\n",
        "        preprocessed_text = self.df['text'].apply(\n",
        "            lambda x: self.text_field.preprocess(x)\n",
        "        )\n",
        "        # load fastext simple embedding with 100d\n",
        "        self.text_field.build_vocab(\n",
        "            preprocessed_text, \n",
        "            vectors='glove.6B.100d'\n",
        "        )\n",
        "\n",
        "        class DataFrameDataset(Dataset):\n",
        "            def __init__(self, df: pd.DataFrame, fields: list):\n",
        "                super(DataFrameDataset, self).__init__(\n",
        "                    [\n",
        "                        Example.fromlist(list(r), fields) for i, r in df.iterrows()\n",
        "                    ], \n",
        "                    fields\n",
        "                )\n",
        "        self.text_dataset = DataFrameDataset(\n",
        "            df=df, \n",
        "            fields=(\n",
        "                ('text', text_field),\n",
        "            )\n",
        "        )\n",
        "\n",
        "        self.text_iter = BucketIterator(\n",
        "            dataset=train_dataset, \n",
        "            batch_size=1\n",
        "        )\n",
        "\n",
        "        # Mapping word classification to 4 numeric classes\n",
        "        for index in range(len(self.humour_arr)):\n",
        "          humour_value = class_humour_weights[self.humour_arr[index]]\n",
        "          sarcasm_value = class_sarcasm_weights[self.sarcasm_arr[index]]\n",
        "          offensive_value = class_offensive_weights[self.offensive_arr[index]]\n",
        "          motivational_value = class_motivational_weights[self.motivational_arr[index]]\n",
        "\n",
        "          if humour_value > sarcasm_value:\n",
        "            if humour_value > offensive_value:\n",
        "              if humour_value > motivational_value:\n",
        "                var = 0\n",
        "              else:\n",
        "                var = 3 \n",
        "            else:\n",
        "              if offensive_value > motivational_value:\n",
        "                var = 2\n",
        "              else: \n",
        "                var = 3\n",
        "          else:\n",
        "            if sarcasm_value > offensive_value:\n",
        "              if sarcasm_value > motivational_value:\n",
        "                var = 1\n",
        "              else:\n",
        "                var = 3\n",
        "            else: \n",
        "              if offensive_value > motivational_value: \n",
        "                var = 2\n",
        "              else:\n",
        "                var = 3\n",
        "\n",
        "          # Creating class vector\n",
        "          lab = [0.0, 0.0, 0.0, 0.0]\n",
        "          lab[var] = 1.0\n",
        "          \n",
        "          # Adding new image class vector to labels array\n",
        "          self.labels.append(lab) \n",
        "\n",
        "        # Calculate of dataset\n",
        "        self.data_len = len(self.data_info.index)\n",
        "        \n",
        "        # Set correct path to images\n",
        "        self.image_arr = images_dir + self.image_arr\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          index (int): index of item to get  \n",
        "\n",
        "        Returns:\n",
        "          Tuple of image, text and class vector as tensors\n",
        "        \"\"\"\n",
        "        img_as_img = None\n",
        "        single_image_name = None\n",
        "\n",
        "        try:\n",
        "          # Get image name from pandas df\n",
        "          single_image_name = self.image_arr[index]\n",
        "\n",
        "          # # Open image with PIL and convert to RGB image\n",
        "          img = Image.open(single_image_name).convert('RGB')\n",
        "          if self.debug==True:\n",
        "            print('1:', img)\n",
        "\n",
        "          # Transform image and convert to tensor\n",
        "          img_as_tensor = self.data_transforms(img)\n",
        "\n",
        "          if self.debug==True:\n",
        "            print('2:', img_as_tensor)\n",
        "\n",
        "          # Get class vector of the image from labels array\n",
        "          label = self.labels[index]\n",
        "\n",
        "          if self.debug==True:\n",
        "            print('3:',label)\n",
        "\n",
        "          # Convert class vector to tensor\n",
        "          label = torch.as_tensor(label)\n",
        "          \n",
        "          if self.debug==True:\n",
        "            print('4:',label)\n",
        "\n",
        "          text_data = next(iter(self.text_iter)).text\n",
        "\n",
        "          if self.debug==True:\n",
        "            print('5:',text_data)\n",
        "\n",
        "          return (img_as_tensor, text_data, label)\n",
        "        except:\n",
        "          print(\"Image loading error for:\",single_image_name)\n",
        "          return ('ERROR', torch.tensor([-1]))\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.data_len    \n"
      ],
      "metadata": {
        "id": "ciwGsrcWkQDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TestDataset('MemotionAnalysis/labels.csv', low_data_mode=False, debug=False)\n",
        "\n",
        "# Loading dataset into DataLoader and setting batch_size\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=4, shuffle=False, num_workers=1)"
      ],
      "metadata": {
        "id": "AR7pRxEUx2XD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, text, label = next(iter(dataloader))\n",
        "print(image.shape)\n",
        "print(text.shape)\n",
        "print(label.shape)"
      ],
      "metadata": {
        "id": "IPTM_Gd6yZeM",
        "outputId": "96eee21c-7381-441b-d1e8-ad3020ccc3f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "torch.Size([4, 50, 1])\n",
            "torch.Size([4, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_model, image_model = None, None\n",
        "if use_trained_model:\n",
        "    text_model_dict = torch.load(text_load_model_path, map_location=torch.device('cpu') if not use_gpu else None)\n",
        "    image_model_dict = torch.load(image_load_model_path, map_location=torch.device('cpu') if not use_gpu else None)\n",
        "    vgg16 = models.vgg16_bn()\n",
        "    vgg16.load_state_dict(torch.load(\"/content/vgg16_bn.pth\")) \n",
        "    image_model = custom_vgg16(vgg16)\n",
        "    model_param = ModelParam(\n",
        "    param_dict=dict(\n",
        "        vocab_size=len(text_field.vocab),\n",
        "        input_size=50,\n",
        "        embedding_dim=100,\n",
        "        target_dim=4\n",
        "        )\n",
        "    )\n",
        "    text_model = TextModel(model_param)\n",
        "    image_model.load_state_dict(image_model_dict)\n",
        "    text_model.load_state_dict(text_model_dict)\n",
        "else:\n",
        "    text_model = train_text_model\n",
        "    image_model = vgg16"
      ],
      "metadata": {
        "id": "a9_dXxxurkAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_model)\n",
        "print(image_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0CymgUquPvY",
        "outputId": "fdc0715b-0863-48e4-eb03-a37f3e917295"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TextModel(\n",
            "  (embedding): Embedding(13676, 100)\n",
            "  (conv): Conv1d(50, 4, kernel_size=(1,), stride=(1,))\n",
            "  (max_pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (lstm): LSTM(50, 16)\n",
            "  (fc): Linear(in_features=16, out_features=1, bias=True)\n",
            "  (sigm): Sigmoid()\n",
            ")\n",
            "custom_vgg16(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (pooling): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (fc): Linear(in_features=25088, out_features=4, bias=True)\n",
            "  (sigm): Sigmoid()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_labels_as_indices(labels_data):\n",
        "    return torch.flatten(torch.max(labels_data, 1)[1]).float()"
      ],
      "metadata": {
        "id": "kIIs7eKhas9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(image_data, text_data):\n",
        "    image_pred = image_model(image_data)\n",
        "    text_pred = torch.squeeze(text_model(text_data))\n",
        "    preds = image_pred*0.3 + text_pred*0.7\n",
        "    images_preds = get_labels_as_indices(image_pred)\n",
        "    text_preds = get_labels_as_indices(text_pred)\n",
        "    print(f\"Image pred: {images_preds}\")\n",
        "    print(f\"Text pred: {text_preds}\")\n",
        "    preds = get_labels_as_indices(preds)\n",
        "    return preds"
      ],
      "metadata": {
        "id": "1dz2aOItwvhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# image_inputs, image_classes = next(iter(dataloader))\n",
        "# text_data = next(iter(train_iter))\n",
        "\n",
        "image_data, text_data, label = next(iter(dataloader))\n",
        "\n",
        "preds = predict(image_data, torch.squeeze(text_data))\n",
        "\n",
        "print(preds)\n",
        "print(get_labels_as_indices(label))\n",
        "# print(get_labels_as_indices(text_data.label))"
      ],
      "metadata": {
        "id": "kITwhpuTxgX6",
        "outputId": "610a3d34-0372-4b41-c4a0-05417c85474e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image pred: tensor([2., 2., 2., 1.])\n",
            "Text pred: tensor([3., 3., 3., 1.])\n",
            "tensor([2., 2., 3., 1.])\n",
            "tensor([2., 1., 0., 3.])\n"
          ]
        }
      ]
    }
  ]
}