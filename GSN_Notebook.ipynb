{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GSN_Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tyluuus/MemotionAnalysis/blob/main/GSN_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GSN21Z Projekt "
      ],
      "metadata": {
        "id": "1rBvyUIKhIm3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Celem projektu będzie realizacja tasku B znajdującego się pod challengem Memotion na platformie Kaggle: https://www.kaggle.com/williamscott701/memotion-dataset-7k\n",
        "\n",
        "\n",
        "Treść zadania: *Task B- Humor Classification: Given an Internet meme, the system has to identify the type of humor expressed. The categories are sarcastic, humorous, and offensive meme. If a meme does not fall under any of these categories, then it is marked as another meme. A meme can have more than one category.*\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HzZuFchUhK59"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset: W datasecie znajduje się 6992 memów pobranych z platformy reddit oraz oznaczonych z wykorzystaniem usługi Amazon Mechanical Turk. Oznaczenia znajdują się w pliku csv, który zawiera: \n",
        "1.   Nazwę pliku z memem\n",
        "2.   Tekst uzyskany z wykorzystaniem OCR\n",
        "3.   Tekst poprawiony\n",
        "4.   Klasa humorystyczna\n",
        "5.   Klasa sarkastyczna\n",
        "6.   Klasa ofensywna\n",
        "7.   Klasa motywacyjna\n"
      ],
      "metadata": {
        "id": "E0WtWWldhMuM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gałąź przetwarzania obrazów"
      ],
      "metadata": {
        "id": "NtI-EnR9hPkt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use trained model variable\n",
        "use_trained_model = False\n",
        "save_model = True\n",
        "image_save_model_path = './drive/MyDrive/GSN_dataset/memotion_images_model_30_epoch.pt'\n",
        "text_save_model_path = './drive/MyDrive/GSN_dataset/memotion_text_model_1_epoch.pt'\n",
        "image_load_model_path = './MemotionAnalysis/memotion_images_model_1_epoch.pt'\n",
        "text_load_model_path = './MemotionAnalysis/memotion_text_model_1_epoch.pt'"
      ],
      "metadata": {
        "id": "B6v2cyDH1dKR"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_epochs = 1 # 250\n",
        "image_epochs = 10 # 20\n",
        "text_batch_size = 4\n",
        "image_batch_size = 16\n",
        "\n",
        "same_batch_size = 4"
      ],
      "metadata": {
        "id": "XYO4NllQebSK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sklonowanie repozytorium z githuba - pobranie plików składających się na dataset - zdjęć oraz pliku csv\n",
        "#pobierane są również pliki niezbędne do wczytania modelu sieci\n",
        "!git clone https://github.com/Tyluuus/MemotionAnalysis.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qo0BnasUhoIN",
        "outputId": "ec00795c-b73c-40d0-f797-78b17657df7a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MemotionAnalysis'...\n",
            "remote: Enumerating objects: 7054, done.\u001b[K\n",
            "remote: Counting objects: 100% (31/31), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 7054 (delta 13), reused 8 (delta 2), pack-reused 7023\u001b[K\n",
            "Receiving objects: 100% (7054/7054), 809.00 MiB | 33.06 MiB/s, done.\n",
            "Resolving deltas: 100% (36/36), done.\n",
            "Checking out files: 100% (13991/13991), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Temporary\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CN4cy6KZsxUj",
        "outputId": "716c85d3-d78c-4d42-c01f-29f2eaba8858"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Imports\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import cv2\n",
        "import time\n",
        "import copy\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets, models\n",
        "from PIL import Image\n",
        "from google.colab.patches import cv2_imshow\n",
        "from torchtext.legacy.data import Dataset, Example, Field\n",
        "from torchtext.legacy.data import BucketIterator"
      ],
      "metadata": {
        "id": "4aknJXfFqGaI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionaries for mapping word classification\n",
        "class_humour_weights = {\"hilarious\": 3, \"not_funny\": 0, \"very_funny\": 2, \"funny\": 1}\n",
        "class_sarcasm_weights = {\"general\": 1, \"not_sarcastic\": 0, \"twisted_meaning\": 2, \"very_twisted\": 3}\n",
        "class_offensive_weights = {\"not_offensive\": 0, \"slight\": 1, \"very_offensive\": 2, \"hateful_offensive\": 3}\n",
        "class_motivational_weights = {\"not_motivational\": 0, \"motivational\": 1}\n",
        "\n",
        "# Directory containing images\n",
        "images_dir = \"./MemotionAnalysis/images/\""
      ],
      "metadata": {
        "id": "v6vAEOVpsjht"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading custom dataset into PyTorch class\n",
        "class MyCustomDataset(Dataset):\n",
        "    def __init__(self, csv_path, low_data_mode=False, debug=False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          csv_path (string): path to csv file  \n",
        "          debug (boolean): debug mode toogle\n",
        "        \"\"\"\n",
        "        # If system is in debug mode\n",
        "        self.debug = debug\n",
        "\n",
        "\n",
        "        # Read the csv_file\n",
        "        if low_data_mode==True:\n",
        "          self.data_info = pd.read_csv(csv_path, header = 6952)\n",
        "        else:\n",
        "          self.data_info = pd.read_csv(csv_path, header = 3)\n",
        "\n",
        "        # Column containing image names\n",
        "        self.image_arr = np.asarray(self.data_info.iloc[:, 1])\n",
        "        # Columns containing emotions classification\n",
        "        self.humour_arr = np.asarray(self.data_info.iloc[:, 4])\n",
        "        self.sarcasm_arr = np.asarray(self.data_info.iloc[:, 5])\n",
        "        self.offensive_arr = np.asarray(self.data_info.iloc[:, 6])\n",
        "        self.motivational_arr = np.asarray(self.data_info.iloc[:, 7])\n",
        "        \n",
        "        # Transforms performed on loaded image\n",
        "        self.data_transforms = transforms.Compose([\n",
        "                                      transforms.Resize((224, 224)),\n",
        "                                      transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "        \n",
        "        # Array with class vectors for each image\n",
        "        self.labels = []\n",
        "\n",
        "        # Mapping word classification to 4 numeric classes\n",
        "        for index in range(len(self.humour_arr)):\n",
        "          humour_value = class_humour_weights[self.humour_arr[index]]\n",
        "          sarcasm_value = class_sarcasm_weights[self.sarcasm_arr[index]]\n",
        "          offensive_value = class_offensive_weights[self.offensive_arr[index]]\n",
        "          motivational_value = class_motivational_weights[self.motivational_arr[index]]\n",
        "\n",
        "          if humour_value > sarcasm_value:\n",
        "            if humour_value > offensive_value:\n",
        "              if humour_value > motivational_value:\n",
        "                var = 0\n",
        "              else:\n",
        "                var = 3 \n",
        "            else:\n",
        "              if offensive_value > motivational_value:\n",
        "                var = 2\n",
        "              else: \n",
        "                var = 3\n",
        "          else:\n",
        "            if sarcasm_value > offensive_value:\n",
        "              if sarcasm_value > motivational_value:\n",
        "                var = 1\n",
        "              else:\n",
        "                var = 3\n",
        "            else: \n",
        "              if offensive_value > motivational_value: \n",
        "                var = 2\n",
        "              else:\n",
        "                var = 3\n",
        "\n",
        "          # Creating class vector\n",
        "          lab = [0.0, 0.0, 0.0, 0.0]\n",
        "          lab[var] = 1.0\n",
        "          \n",
        "          # Adding new image class vector to labels array\n",
        "          self.labels.append(lab) \n",
        "\n",
        "        # Calculate of dataset\n",
        "        self.data_len = len(self.data_info.index)\n",
        "        \n",
        "        # Set correct path to images\n",
        "        self.image_arr = images_dir + self.image_arr\n",
        "\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          index (int): index of item to get  \n",
        "\n",
        "        Returns:\n",
        "          Tuple of image and class vector as tensors\n",
        "        \"\"\"\n",
        "        img_as_img = None\n",
        "        single_image_name = None\n",
        "\n",
        "\n",
        "        try:\n",
        "          # Get image name from pandas df\n",
        "          single_image_name = self.image_arr[index]\n",
        "\n",
        "          # # Open image with PIL and convert to RGB image\n",
        "          img = Image.open(single_image_name).convert('RGB')\n",
        "          if self.debug==True:\n",
        "            print('1:', img)\n",
        "\n",
        "          # Transform image and convert to tensor\n",
        "          img_as_tensor = self.data_transforms(img)\n",
        "\n",
        "          if self.debug==True:\n",
        "            print('2:', img_as_tensor)\n",
        "\n",
        "          # Get class vector of the image from labels array\n",
        "          img_label = self.labels[index]\n",
        "\n",
        "          if self.debug==True:\n",
        "            print('3:',img_label)\n",
        "\n",
        "          # Convert class vector to tensor\n",
        "          img_label = torch.as_tensor(img_label)\n",
        "          \n",
        "          if self.debug==True:\n",
        "            print('4:',img_label)\n",
        "\n",
        "          return (img_as_tensor, img_label)\n",
        "\n",
        "        except:\n",
        "          print(\"Image loading error for:\",single_image_name)\n",
        "          return ('ERROR', torch.tensor([-1]))\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data_len"
      ],
      "metadata": {
        "id": "qAerCA5Gqd_D"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Switch to using GPU\n",
        "\n",
        "use_gpu = torch.cuda.is_available()\n",
        "if use_gpu:\n",
        "    print(\"Using CUDA\")"
      ],
      "metadata": {
        "id": "hEbiFkj3tuUC",
        "outputId": "2c658d23-24da-4851-a2f9-d7d1494325c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using CUDA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading images into custom dataset\n",
        "dataset = MyCustomDataset('MemotionAnalysis/labels.csv', low_data_mode=False)\n",
        "\n",
        "# Loading dataset into DataLoader and setting batch_size\n",
        "b_size = same_batch_size if use_trained_model else image_batch_size\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=b_size, shuffle=False, num_workers=1)\n",
        "dataset_size = len(dataloader)"
      ],
      "metadata": {
        "id": "QyONsUPTtxnL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text preprocessing\n",
        "\n",
        "meme_text = dataset.data_info.iloc[:, 3]\n",
        "\n",
        "raw_df = []\n",
        "\n",
        "for i in range(len(meme_text)):\n",
        "    raw_df.append([str(meme_text[i]), dataset.labels[i]])\n",
        "\n",
        "df = pd.DataFrame(raw_df[:-3], columns=['text', 'label'])\n",
        "\n",
        "text_field = Field(\n",
        "    sequential=True,\n",
        "    tokenize='basic_english', \n",
        "    fix_length=50,\n",
        "    lower=True\n",
        ")\n",
        "label_field = Field(sequential=False, use_vocab=False)\n",
        "# prepocess\n",
        "preprocessed_text = df['text'].apply(\n",
        "    lambda x: text_field.preprocess(x)\n",
        ")\n",
        "# load fastext simple embedding with 100d\n",
        "text_field.build_vocab(\n",
        "    preprocessed_text, \n",
        "    vectors='glove.6B.100d'\n",
        ")"
      ],
      "metadata": {
        "id": "Rptz647rV-0L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16ac463f-6295-45fe-8dd0-da02161ee371"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:43, 5.28MB/s]                           \n",
            "100%|█████████▉| 399999/400000 [00:23<00:00, 17000.92it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DataFrameDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame, fields: list):\n",
        "        super(DataFrameDataset, self).__init__(\n",
        "            [\n",
        "                Example.fromlist(list(r), fields) for i, r in df.iterrows()\n",
        "            ], \n",
        "            fields\n",
        "        )\n",
        "\n",
        "train_dataset, test_dataset = DataFrameDataset(\n",
        "    df=df, \n",
        "    fields=(\n",
        "        ('text', text_field),\n",
        "        ('label', label_field)\n",
        "    )\n",
        ").split(split_ratio=0.85)\n",
        "\n",
        "b_size = same_batch_size if use_trained_model else text_batch_size\n",
        "\n",
        "train_iter, test_iter = BucketIterator.splits(\n",
        "    datasets=(train_dataset, test_dataset), \n",
        "    batch_sizes=(b_size, b_size),\n",
        "    sort=False\n",
        ")"
      ],
      "metadata": {
        "id": "P6qhrLcvWeyu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check loaded data\n",
        "\n",
        "def imshow(inp, title=None):\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    # plt.figure(figsize=(10, 10))\n",
        "    plt.axis('off')\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)\n",
        "\n",
        "def show_databatch(inputs, classes):\n",
        "    out = torchvision.utils.make_grid(inputs)\n",
        "    imshow(out, title=[classes])\n",
        "\n",
        "# Get a batch of training data\n",
        "inputs, classes = next(iter(dataloader))\n",
        "show_databatch(inputs, classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "XQ6mkihFuZ0B",
        "outputId": "d73e218b-e0af-4121-ad19-50cd16ce343a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pretrained model from PyTorch\n",
        "\n",
        "vgg16 = models.vgg16_bn()\n",
        "vgg16.load_state_dict(torch.load(\"./drive/MyDrive/vgg16_bn.pth\")) \n",
        "\n",
        "# Print to see network architecture\n",
        "# print(vgg16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiM8HLi7umZR",
        "outputId": "a8ffd3f2-d0a8-40b0-945f-584d2b422c2d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if use_trained_model==False:\n",
        "\n",
        "  # Class with own modification of VGG16 architecture - classifier was changed - \n",
        "  # after getting features from image there is pooling layer, next results are flattened and feed to fully connected layer with output number = 4\n",
        "  # at the end sigmoid function is used\n",
        "\n",
        "class custom_vgg16(nn.Module):\n",
        "    def __init__(self, model):\n",
        "        super(custom_vgg16, self).__init__()\n",
        "\n",
        "        self.features = list(model.features)\n",
        "        self.features = nn.Sequential(*self.features)\n",
        "        self.pooling = model.avgpool\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc = nn.Linear(in_features=25088, out_features=4, bias=True)\n",
        "        self.sigm = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.features(x)\n",
        "        out = self.pooling(out)\n",
        "        out = self.flatten(out)\n",
        "        out = self.fc(out)\n",
        "        out = self.sigm(out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "7-AWBscoun7-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if use_trained_model==False:\n",
        "\n",
        "class ModelParam(object):\n",
        "    def __init__(self, param_dict: dict = dict()):\n",
        "        self.input_size = param_dict.get('input_size', 0)\n",
        "        self.vocab_size = param_dict.get('vocab_size')\n",
        "        self.embedding_dim = param_dict.get('embedding_dim', 100)\n",
        "        self.target_dim = param_dict.get('target_dim')\n",
        "        \n",
        "class TextModel(nn.Module):\n",
        "    def __init__(self, model_param: ModelParam):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(model_param.vocab_size, model_param.embedding_dim)\n",
        "        self.conv = nn.Conv1d(50, 4, 1)\n",
        "        self.max_pool = nn.MaxPool1d(2)\n",
        "        self.lstm = nn.LSTM(50,16)\n",
        "        self.fc = nn.Linear(in_features=16, out_features=1, bias=True)\n",
        "        self.sigm = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.embedding(x)\n",
        "        features = F.relu(features)\n",
        "        features = self.conv(features)\n",
        "        features = self.max_pool(features)\n",
        "        features, hidden = self.lstm(features)\n",
        "        features = self.fc(features)\n",
        "        features = self.sigm(features)\n",
        "        return features"
      ],
      "metadata": {
        "id": "BFVgxQBzX7Fe"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading custiom VGG16 from loaded, pretrained VGG16 model\n",
        "vgg16 = custom_vgg16(vgg16)\n",
        "\n",
        "if use_trained_model==True:\n",
        "  vgg16.load_state_dict(torch.load('/content/drive/MyDrive/GSN_dataset/memotion_images_model.pt'))"
      ],
      "metadata": {
        "id": "RcNr3Wd6uph2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set VGG16 to run on GPU\n",
        "if use_gpu:\n",
        "    vgg16.cuda()\n",
        "    \n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Define optimizer and LR Scheduler for training\n",
        "optimizer_ft = optim.SGD(vgg16.parameters(), lr=0.0003)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "IW9Ss-wxuu90"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# F1 score calculating for image\n",
        "image_f1_data = {\n",
        "    0: {\n",
        "        \"true_positive\": 0.0,\n",
        "        \"false_positive\": 0.0,\n",
        "        \"false_negative\": 0.0\n",
        "    },\n",
        "    1: {\n",
        "        \"true_positive\": 0.0,\n",
        "        \"false_positive\": 0.0,\n",
        "        \"false_negative\": 0.0\n",
        "    },\n",
        "    2: {\n",
        "        \"true_positive\": 0.0,\n",
        "        \"false_positive\": 0.0,\n",
        "        \"false_negative\": 0.0\n",
        "    },\n",
        "    3: {\n",
        "        \"true_positive\": 0.0,\n",
        "        \"false_positive\": 0.0,\n",
        "        \"false_negative\": 0.0\n",
        "    }\n",
        "}\n",
        "\n",
        "def clear_image_f1_data():\n",
        "    for i in range(4):\n",
        "        image_f1_data[i][\"true_positive\"] = 0.0\n",
        "        image_f1_data[i][\"false_positive\"] = 0.0\n",
        "        image_f1_data[i][\"false_negative\"] = 0.0\n",
        "\n",
        "def update_image_f1_data(preditions: list, labels: list):\n",
        "    for i in range(len(preditions)):\n",
        "        if(preditions[i] == labels[i]):\n",
        "            image_f1_data[labels[i]][\"true_positive\"] += 1.0\n",
        "        else:\n",
        "            image_f1_data[labels[i]][\"false_positive\"] += 1.0\n",
        "            image_f1_data[preditions[i]][\"false_negative\"] += 1.0\n",
        "                \n",
        "\n",
        "def calculate_image_f1_for_class(class_number: int):\n",
        "    precision_divider = image_f1_data[class_number][\"true_positive\"]+image_f1_data[class_number][\"false_positive\"]\n",
        "    precision = (image_f1_data[class_number][\"true_positive\"] / precision_divider) if precision_divider > 0 else 0\n",
        "    recall_divider = image_f1_data[class_number][\"true_positive\"]+image_f1_data[class_number][\"false_negative\"]\n",
        "    recall = (image_f1_data[class_number][\"true_positive\"] / recall_divider) if recall_divider > 0 else 0\n",
        "    #print(f\"Precision: {precision} , Recall: {recall} \")\n",
        "    return (2 * (precision * recall) / (precision + recall)) if (precision + recall) > 0 else 0\n",
        "\n",
        "def calculate_image_macro_f1():\n",
        "    macro_f1 = 0.0\n",
        "    for i in range(4):\n",
        "        macro_f1 += calculate_image_f1_for_class(i)\n",
        "    return macro_f1/4"
      ],
      "metadata": {
        "id": "kU4rv8uUXgPw"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_f1_data = {\n",
        "    0: {\n",
        "        \"true_positive\": 0.0,\n",
        "        \"false_positive\": 0.0,\n",
        "        \"false_negative\": 0.0\n",
        "    },\n",
        "    1: {\n",
        "        \"true_positive\": 0.0,\n",
        "        \"false_positive\": 0.0,\n",
        "        \"false_negative\": 0.0\n",
        "    },\n",
        "    2: {\n",
        "        \"true_positive\": 0.0,\n",
        "        \"false_positive\": 0.0,\n",
        "        \"false_negative\": 0.0\n",
        "    },\n",
        "    3: {\n",
        "        \"true_positive\": 0.0,\n",
        "        \"false_positive\": 0.0,\n",
        "        \"false_negative\": 0.0\n",
        "    }\n",
        "}\n",
        "\n",
        "def clear_text_f1_data():\n",
        "    for i in range(4):\n",
        "        text_f1_data[i][\"true_positive\"] = 0.0\n",
        "        text_f1_data[i][\"false_positive\"] = 0.0\n",
        "        text_f1_data[i][\"false_negative\"] = 0.0\n",
        "\n",
        "def update_text_f1_data(preditions: list, labels: list):\n",
        "    for i in range(len(preditions)):\n",
        "        if(preditions[i] == labels[i]):\n",
        "            text_f1_data[labels[i]][\"true_positive\"] += 1.0\n",
        "        else:\n",
        "            text_f1_data[labels[i]][\"false_positive\"] += 1.0\n",
        "            text_f1_data[preditions[i]][\"false_negative\"] += 1.0\n",
        "                \n",
        "\n",
        "def calculate_text_f1_for_class(class_number: int):\n",
        "    if text_f1_data[class_number][\"true_positive\"] == 0:\n",
        "      return 0\n",
        "    precision = text_f1_data[class_number][\"true_positive\"] / (text_f1_data[class_number][\"true_positive\"]+text_f1_data[class_number][\"false_positive\"])\n",
        "    recall = text_f1_data[class_number][\"true_positive\"] / (text_f1_data[class_number][\"true_positive\"]+text_f1_data[class_number][\"false_negative\"])\n",
        "    # print(f\"Precision: {precision} , Recall: {recall} \")\n",
        "    return 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "def calculate_text_macro_f1():\n",
        "    macro_f1 = 0.0\n",
        "    for i in range(4):\n",
        "        macro_f1 += calculate_text_f1_for_class(i)\n",
        "    return macro_f1/4"
      ],
      "metadata": {
        "id": "qgTTp_11Xc7i"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classes_convert(classes):\n",
        "  clas = []\n",
        "  for element in range(len(classes)):\n",
        "    var = classes[element]\n",
        "    for index in range(len(var)):\n",
        "      if var[index]==1:\n",
        "        clas.append(index)\n",
        "  return torch.tensor(clas)"
      ],
      "metadata": {
        "id": "vEeAe-_azz_h"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining training model\n",
        "def train_model(vgg, criterion, optimizer, scheduler, num_epochs=1, debug=False):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      vgg (nn.Model): Neural Network model to traing\n",
        "      criterion (nn.LossFunction): Loss Function \n",
        "      optimizer (torch.optim): Optimalization Function\n",
        "      scheduler (torch.optim.lr_scheduler): Learning Rate Scheduler\n",
        "      num_epochs (int): Number of training epochs\n",
        "      debug (boolean): Debug mode toogle\n",
        "    \"\"\"\n",
        "\n",
        "    since = time.time()\n",
        "    best_model_wts = copy.deepcopy(vgg.state_dict())\n",
        "    best_acc = 0.0\n",
        "    avg_loss = 0\n",
        "    avg_acc = 0\n",
        "    avg_loss_val = 0\n",
        "    avg_acc_val = 0\n",
        "    \n",
        "    train_batches = len(dataloader)\n",
        "    val_batches = len(dataloader)\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        print(\"Epoch {}/{}\".format(epoch, num_epochs))\n",
        "        print('-' * 10)\n",
        "        \n",
        "        loss_train = 0\n",
        "        loss_val = 0\n",
        "        acc_train = 0\n",
        "        acc_val = 0\n",
        "        target_true = 0\n",
        "        predicted_true = 0\n",
        "        correct_true = 0\n",
        "        \n",
        "        vgg.train(True)\n",
        "        clear_image_f1_data()\n",
        "        for inputs, classes in iter(dataloader):\n",
        "            if use_gpu:\n",
        "                sample, clas = Variable(inputs.cuda()), Variable(classes.cuda())\n",
        "            else:\n",
        "                sample, clas = Variable(inputs), Variable(classes)\n",
        "            \n",
        "            # addressing batch labels to list\n",
        "            batch_labels = []\n",
        "            for row in clas.data:\n",
        "              for i in range(len(row)):\n",
        "                if row[i] == 1:\n",
        "                  batch_labels.append(i)\n",
        "            \n",
        "            if use_gpu:\n",
        "              batch_labels = torch.tensor(batch_labels).cuda()\n",
        "            else:\n",
        "              batch_labels = torch.tensor(batch_labels)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            outputs = vgg(sample)\n",
        "\n",
        "            if debug==True:\n",
        "              print(outputs)\n",
        "              print(clas)\n",
        "\n",
        "            _, preds = torch.max(outputs.data, -1)\n",
        "            loss = criterion(outputs, clas)\n",
        "            \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            update_image_f1_data(preds.squeeze().tolist(), batch_labels.squeeze().tolist())\n",
        "            \n",
        "            del sample, clas, outputs, preds\n",
        "            torch.cuda.empty_cache()\n",
        "        \n",
        "        epoch_train_macro_f1 = calculate_image_macro_f1()\n",
        "        \n",
        "        vgg.train(False)\n",
        "        vgg.eval()\n",
        "        clear_image_f1_data()    \n",
        "        for inputs, classes in iter(dataloader):\n",
        "            if use_gpu:\n",
        "                inputs, labels = Variable(inputs.cuda()), Variable(classes.cuda())\n",
        "            else:\n",
        "                inputs, labels = Variable(inputs), Variable(classes)\n",
        "\n",
        "            # addressing batch labels to list\n",
        "            batch_labels = []\n",
        "            for row in labels.data:\n",
        "              for i in range(len(row)):\n",
        "                if row[i] == 1:\n",
        "                  batch_labels.append(i)\n",
        "            \n",
        "            if use_gpu:\n",
        "              batch_labels = torch.tensor(batch_labels).cuda()\n",
        "            else:\n",
        "              batch_labels = torch.tensor(batch_labels)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            outputs = vgg(inputs)\n",
        "            \n",
        "            # Prediction\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            if debug==True:\n",
        "              print(\"Preds: \",preds)\n",
        "            loss = criterion(outputs, labels)\n",
        "            if debug==True:\n",
        "              print(\"[1]Classes shape: \",classes.shape)\n",
        "              print(\"[1]Classes: \",classes)\n",
        "\n",
        "            classes = classes_convert(classes)\n",
        "            if debug==True:\n",
        "              print(\"[2]Classes: \",classes.shape)\n",
        "              print(\"[2]Classes: \",classes)\n",
        "            \n",
        "            update_image_f1_data(preds.squeeze().tolist(), batch_labels.squeeze().tolist())\n",
        "            del inputs, labels, outputs, preds\n",
        "            torch.cuda.empty_cache()\n",
        "        \n",
        "        epoch_val_macro_f1 = calculate_image_macro_f1()\n",
        "\n",
        "        print()\n",
        "        print(\"Epoch {} result: \".format(epoch))\n",
        "        print(\"F1 score: {:.4f} (train), {:.4f} (val)\".format(epoch_train_macro_f1, epoch_val_macro_f1))\n",
        "        print('-' * 10)\n",
        "        print()\n",
        "        \n",
        "        if avg_acc_val > best_acc:\n",
        "            best_acc = avg_acc_val\n",
        "            best_model_wts = copy.deepcopy(vgg.state_dict())\n",
        "        \n",
        "    elapsed_time = time.time() - since\n",
        "    print()\n",
        "    print(\"Training completed in {:.0f}m {:.0f}s\".format(elapsed_time // 60, elapsed_time % 60))\n",
        "    print(\"Best acc: {:.4f}\".format(best_acc))\n",
        "    \n",
        "    vgg.load_state_dict(best_model_wts)\n",
        "    return vgg"
      ],
      "metadata": {
        "id": "d_glLctDu338"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_classes_convert(classes):\n",
        "  y = classes\n",
        "  # Actual conversion using y elements as index \n",
        "  M = np.zeros(len(y))\n",
        "\n",
        "  for i in range(len(y)):\n",
        "    M[i]=torch.argmax(y[i])\n",
        "  return torch.tensor(M)"
      ],
      "metadata": {
        "id": "8HoqPaoUYVj_"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text model train\n",
        "\n",
        "if use_trained_model==False:\n",
        "    model_param = ModelParam(\n",
        "    param_dict=dict(\n",
        "        vocab_size=len(text_field.vocab),\n",
        "        input_size=50,\n",
        "        embedding_dim=100,\n",
        "        target_dim=4\n",
        "        )\n",
        "    )\n",
        "    train_text_model = TextModel(model_param)\n",
        "    loss_function = nn.BCELoss()\n",
        "    optimizer = optim.SGD(train_text_model.parameters(), lr=0.0003)\n",
        "\n",
        "    for epoch in range(text_epochs):\n",
        "        train_text_model.train()\n",
        "        clear_text_f1_data()\n",
        "        b_num = 0\n",
        "        epoch_num = 0\n",
        "        for batch in train_iter:\n",
        "            optimizer.zero_grad()\n",
        "            prediction = train_text_model(batch.text.T)\n",
        "            batch_label = batch.label.to(torch.float)\n",
        "            labels = text_classes_convert(batch_label)\n",
        "            preds = torch.flatten(torch.max(prediction, 1)[1]).float()\n",
        "            loss = loss_function(torch.squeeze(prediction), batch.label.to(torch.float))\n",
        "            update_text_f1_data(preds.squeeze().tolist(), labels.squeeze().tolist())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        \n",
        "        train_text_macro_f1 = calculate_text_macro_f1()\n",
        "        \n",
        "        train_text_model.eval()\n",
        "        clear_text_f1_data()\n",
        "        for batch in test_iter:\n",
        "            with torch.no_grad():\n",
        "                prediction = train_text_model(batch.text.T)\n",
        "                batch.label = batch.label.to(torch.float)\n",
        "                labels = text_classes_convert(batch_label)\n",
        "                preds = torch.flatten(torch.max(prediction, 1)[1]).float()\n",
        "                loss = loss_function(torch.squeeze(prediction), batch.label.to(torch.float))\n",
        "                update_text_f1_data(preds.squeeze().tolist(), labels.squeeze().tolist())\n",
        "        \n",
        "        val_text_macro_f1 = calculate_text_macro_f1()\n",
        "        print()\n",
        "        print(\"Epoch {} result: \".format(epoch))\n",
        "        print(\"F1 score: {:.4f} (train), {:.4f} (val)\".format(train_text_macro_f1, val_text_macro_f1))\n",
        "        print('-' * 10)\n",
        "        print()\n",
        "    if save_model:\n",
        "        torch.save(train_text_model.state_dict(), text_save_model_path)\n",
        "        print(\"Text model saved\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjVN5puCYh1G",
        "outputId": "41418ded-7e54-495a-dacf-5a15b92414a5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 0 result: \n",
            "F1 score: 0.2238 (train), 0.1694 (val)\n",
            "----------\n",
            "\n",
            "Text model saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if use_trained_model==False:\n",
        "  vgg16 = train_model(vgg16, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=image_epochs, debug=False)\n",
        "  if save_model:\n",
        "    torch.save(vgg16.state_dict(), image_save_model_path)\n",
        "    print(\"Image model saved\")"
      ],
      "metadata": {
        "id": "8V6CUYAQu6A6",
        "outputId": "e858dc6d-c531-4953-d2df-aafe7dc8fbed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 0 result: \n",
            "F1 score: 0.2279 (train), 0.2201 (val)\n",
            "----------\n",
            "\n",
            "Epoch 1/20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1 result: \n",
            "F1 score: 0.2110 (train), 0.2194 (val)\n",
            "----------\n",
            "\n",
            "Epoch 2/20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2 result: \n",
            "F1 score: 0.2191 (train), 0.2254 (val)\n",
            "----------\n",
            "\n",
            "Epoch 3/20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3 result: \n",
            "F1 score: 0.2268 (train), 0.2289 (val)\n",
            "----------\n",
            "\n",
            "Epoch 4/20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4 result: \n",
            "F1 score: 0.2334 (train), 0.2370 (val)\n",
            "----------\n",
            "\n",
            "Epoch 5/20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5 result: \n",
            "F1 score: 0.2424 (train), 0.2413 (val)\n",
            "----------\n",
            "\n",
            "Epoch 6/20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 6 result: \n",
            "F1 score: 0.2527 (train), 0.2466 (val)\n",
            "----------\n",
            "\n",
            "Epoch 7/20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 7 result: \n",
            "F1 score: 0.2597 (train), 0.2580 (val)\n",
            "----------\n",
            "\n",
            "Epoch 8/20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 8 result: \n",
            "F1 score: 0.2643 (train), 0.2681 (val)\n",
            "----------\n",
            "\n",
            "Epoch 9/20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 9 result: \n",
            "F1 score: 0.2726 (train), 0.2667 (val)\n",
            "----------\n",
            "\n",
            "Epoch 10/20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 10 result: \n",
            "F1 score: 0.2781 (train), 0.2799 (val)\n",
            "----------\n",
            "\n",
            "Epoch 11/20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 11 result: \n",
            "F1 score: 0.2846 (train), 0.2858 (val)\n",
            "----------\n",
            "\n",
            "Epoch 12/20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 12 result: \n",
            "F1 score: 0.2943 (train), 0.2901 (val)\n",
            "----------\n",
            "\n",
            "Epoch 13/20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 13 result: \n",
            "F1 score: 0.3083 (train), 0.2926 (val)\n",
            "----------\n",
            "\n",
            "Epoch 14/20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 14 result: \n",
            "F1 score: 0.3121 (train), 0.3029 (val)\n",
            "----------\n",
            "\n",
            "Epoch 15/20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 15 result: \n",
            "F1 score: 0.3191 (train), 0.3093 (val)\n",
            "----------\n",
            "\n",
            "Epoch 16/20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 16 result: \n",
            "F1 score: 0.3247 (train), 0.3188 (val)\n",
            "----------\n",
            "\n",
            "Epoch 17/20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 17 result: \n",
            "F1 score: 0.3390 (train), 0.3223 (val)\n",
            "----------\n",
            "\n",
            "Epoch 18/20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 18 result: \n",
            "F1 score: 0.3371 (train), 0.3330 (val)\n",
            "----------\n",
            "\n",
            "Epoch 19/20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 19 result: \n",
            "F1 score: 0.3505 (train), 0.3438 (val)\n",
            "----------\n",
            "\n",
            "\n",
            "Training completed in 132m 12s\n",
            "Best acc: 0.0000\n",
            "Image model saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_model, image_model = None, None\n",
        "if use_trained_model:\n",
        "    text_model_dict = torch.load(text_load_model_path, map_location=torch.device('cpu') if not use_gpu else None)\n",
        "    image_model_dict = torch.load(image_load_model_path, map_location=torch.device('cpu') if not use_gpu else None)\n",
        "    image_model = custom_vgg16(vgg16)\n",
        "    model_param = ModelParam(\n",
        "    param_dict=dict(\n",
        "        vocab_size=len(text_field.vocab),\n",
        "        input_size=50,\n",
        "        embedding_dim=100,\n",
        "        target_dim=4\n",
        "        )\n",
        "    )\n",
        "    text_model = TextModel(model_param)\n",
        "    image_model.load_state_dict(image_model_dict)\n",
        "    text_model.load_state_dict(text_model_dict)\n",
        "else:\n",
        "    text_model = train_text_model\n",
        "    image_model = vgg16"
      ],
      "metadata": {
        "id": "a9_dXxxurkAt"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_model)\n",
        "print(image_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0CymgUquPvY",
        "outputId": "c0f2dfb4-3751-4945-abc3-2b27e9a854c9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TextModel(\n",
            "  (embedding): Embedding(13676, 100)\n",
            "  (conv): Conv1d(50, 4, kernel_size=(1,), stride=(1,))\n",
            "  (max_pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (lstm): LSTM(50, 16)\n",
            "  (fc): Linear(in_features=16, out_features=1, bias=True)\n",
            "  (sigm): Sigmoid()\n",
            ")\n",
            "custom_vgg16(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (pooling): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (fc): Linear(in_features=25088, out_features=4, bias=True)\n",
            "  (sigm): Sigmoid()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_labels_as_indices(labels_data):\n",
        "    return torch.flatten(torch.max(labels_data, 1)[1]).float()"
      ],
      "metadata": {
        "id": "kIIs7eKhas9D"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(image_data, text_data):\n",
        "    image_pred = image_model(image_data)\n",
        "    text_pred = torch.squeeze(text_model(text_data))\n",
        "    preds = image_pred*0.3 + text_pred*0.7\n",
        "    images_preds = get_labels_as_indices(image_pred)\n",
        "    text_preds = get_labels_as_indices(text_pred)\n",
        "    print(f\"Image pred: {images_preds}\")\n",
        "    print(f\"Text pred: {text_preds}\")\n",
        "    preds = get_labels_as_indices(preds)\n",
        "    return preds"
      ],
      "metadata": {
        "id": "1dz2aOItwvhp"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_inputs, image_classes = next(iter(dataloader))\n",
        "text_data = next(iter(train_iter))\n",
        "\n",
        "preds = predict(image_inputs, text_data.text.T)\n",
        "\n",
        "print(preds)\n",
        "print(get_labels_as_indices(image_classes))\n",
        "print(get_labels_as_indices(text_data.label))"
      ],
      "metadata": {
        "id": "kITwhpuTxgX6",
        "outputId": "95e7798c-3b12-4158-b197-62ea49602f27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-36ac663c8289>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtext_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-0a4defed2a07>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(image_data, text_data)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mimage_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtext_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_pred\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.3\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtext_pred\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mimages_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_labels_as_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-458a8adaba06>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    442\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 443\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor"
          ]
        }
      ]
    }
  ]
}